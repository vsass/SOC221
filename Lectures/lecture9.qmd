---
title: '<h1 style="font-size:3em; "> Bivariate regression &<br>Inference for regression </h1>'
title-slide-attributes:
  data-background-image: ../images/abstract_statistics_playful2.jpeg
  data-background-size: cover
  data-background-opacity: "0.33"
subtitle: "SOC 221 • Lecture 9"
author: "Victoria Sass"
date: "July 24, 2024"
date-format: full
execute: 
  echo: true
  message: false
  warning: false
format: 
  revealjs:
    reference-location: margin
    theme: lecture_styles.scss
    controls: true
    slide-number: true
    chalkboard: true
    incremental: false 
    smaller: true
    preview-links: true
    history: false
    progress: true
    link-external-icon: true 
---

```{r}
#| echo: false
#| cache: false
require(tidyverse)
require(ggthemes)
require(gt)
require(gganimate)
require(ggforce)
options(scipen = 1000)

knitr::opts_chunk$set(comment = ">")

# set transparent background in base
knitr::opts_chunk$set(dev.args=list(bg='transparent'))

# set transparent background in ggplot
ggplot2::theme_set(ggthemes::theme_tufte(base_size=12))
ggplot2::theme_update(panel.background = ggplot2::element_blank(),
                      plot.background=ggplot2::element_blank(),
    legend.background=ggplot2::element_blank())

options(width=80, show.signif.stars=FALSE)
```

# Bivariate regression {.section-title background-color="#c5b4e3"}

## Correlation and Regression

<br>

::: {style="font-size: 1.5em; text-align: center"}
The two most common tool for measuring <br> associations between [interval]{.underline} variables
:::

:::: {.columns}

::: {.column width="50%"}

::: {.fragment fragment-index=1 style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
**CORRELATION**
:::

::: {.fragment fragment-index=3 style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1em"}
[[**standardized**]{.underline} summary of association between our variables]{style="font-size: 1.25em"}

* does not depend on the units of the variables
    * always 0 to |1.0|
* allows for comparison of associations between different pairs of variables
:::

:::

::: {.column width="50%"}

::: {.fragment fragment-index=1 style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
**REGRESSION**
:::

::: {.fragment fragment-index=4 style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center;"}
[characterizes the [**substantive**]{.underline} effect of X on Y]{style="font-size: 1.25em"}

* how much Y differs across different values of X
* conveyed in units of our specific independent and dependent variables
:::

:::

::::

::: {.fragment .fade-out fragment-index=3}
::: {.fragment fragment-index=2 style="position: absolute; bottom: 0px; left: 0px; width: 500px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4.5

set.seed(3)
earnings_age <- tibble(Age = sample(18:70, size = 50, replace = TRUE), 
                       Earnings = Age * 3 + rnorm(n = 50, mean = 60, sd = 50))

ggplot(earnings_age, aes(x = Age, y = Earnings)) + 
  geom_point(size = 4, color = "#e93cac") +
  theme_tufte(base_size = 22) 
```
:::
:::

::: {.fragment .fade-out fragment-index=3}
::: {.fragment fragment-index=2 style="border: 3px solid #e93cac; margin: 5px; position: absolute; bottom: 100px; right: 0px; width: 500px; text-align: center"}
Both correlation and regression are based on a description of a line used to characterize data points in a scatterplot
:::
:::

## Correlation vs. bivariate regression

:::: {.columns}

::: {.column width="50%"}
```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3.5

library(smplot2)
set.seed(123)
data1 <- tibble(x = rnorm(50, 4, 3), y = x + rnorm(25, 3, 6))

ggplot(data = data1, aes(x = x, y = y)) +
  geom_point(color = "#1b8883", size = 3) + 
  sm_statCorr(color = "#e93cac", linetype = "dashed", label_x = -1.5, label_y = 20, separate_by = "\n", text_size = 8, linewidth = 2) +
  theme_tufte(base_size = 18) + 
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())
```

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3.5

set.seed(123)
data2 <- tibble(x = rnorm(50, 4, 3), y = x* -1 + rnorm(25, 4, 0.5))

ggplot(data = data2, aes(x = x, y = y)) +
  geom_point(color = "#1b8883", size = 3) + 
  sm_statCorr(color = "#e93cac", linetype = "dashed", label_x = 0, label_y = -4, separate_by = "\n", text_size = 8, linewidth = 2) + 
  theme_tufte(base_size = 18) + 
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())
```
:::
  
::: {.column width="50%"}

::: {.fragment style="border: 3px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px;"}
[Correlation:]{.underline .center style="color: #a68100;"}

* assess how tightly clustered points in the scatterplot around a line
:::

<br>

::: {.fragment style="border: 3px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px;"}
[Bivariate Regression:]{.underline .center style="color: #754cbc"}

* describe the line that characterizes the points in the scatterplot
* tells us how the dependent (Y) variable changes for a one-unit change in the independent (X) variable
* allows us to [**predict**]{.underline style="color: #e93cac"} values of Y based on values of X
:::

:::
  
::::

----

::: {style="font-size: 1.4em; color: #e93cac"}
Examples of questions bivariate regression can help us answer:
:::

<br>

::: {.incremental style="font-size: 1.25em;"}
* What kind of GPA would we predict for someone who studies for 15 hours per week?
* Based on the data, how many dates would we predict for a person with a GPA of 3.5?
* If someone has 16 years of education, what is our best prediction of their income?
:::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}
::: {.fragment fragment-index=1 style="color: #1b8883; text-align: center"}
Draw a scatterplot
:::

::: {style="color: #e8e3d3; text-align: center"}
Use a line to describe the<br>pattern of points
:::

```{r}
#| echo: false

educ_income <- tibble(Education = c(12, 16, 13, 14, 8, 15, 16, 16, 11, 20, 17, 2), 
                      Income = c(26000, 33000, 27750, 29500, 19000, 31250, 33000, 33000, 24250, 40000, 34750, 8500))

educ_income |> gt() |> 
  cols_align(align = "center", columns = everything()) |> # center columns
  tab_options(table.background.color = "#e8e3d3", table.font.size = px(16L)) |>
  opt_table_outline(color = "#85754d") # outline table with colored border
```


:::
  
::: {.column width="60%"}

::: {style="color: #e8e3d3; text-align: center; font-size: 1.5em"}
Can use this line to predict the level of income for a person with any level of education <br> *(within the range that we observe)*
:::

::: {.fragment fragment-index=1}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

ggplot(educ_income, aes(x = Education, y = Income)) + 
  labs(x = "Education (in years)") +
  geom_point(color = "#1b8883", size = 4, alpha = 0.75) +
  annotate(geom = "segment", x = 0, xend = 20, y = 5000, yend = 40000, color = "#a68100", alpha = 0, linewidth = 2) +
  annotate(geom = "segment", alpha = 0, x = 9, y = 0, yend = 20750, linetype = 2, color = "#754cbc", linewidth = 1.5) + # dashed line
  annotate(geom = "segment", alpha = 0, x = 9,  y = 20250, yend = 20750, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  annotate(geom = "segment", alpha = 0, x = 9, y = 20750, xend = 0, linetype = 2, color = "#754cbc", linewidth = 1.5, lineend = "round", linejoin = "round") +
  annotate(geom = "segment", alpha = 0, x = 0,  y = 20750, xend = -0.25, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  annotate(geom = "segment", alpha = 0, x = 15, y = 0, yend = 31250, linetype = 2, color = "#754cbc", linewidth = 1.5, lineend = "round", linejoin = "round") +
  annotate(geom = "segment", alpha = 0, x = 15,  y = 30750, yend = 31250, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  annotate(geom = "segment", alpha = 0, x = 15, y = 31250, xend = 0, linetype = 2, color = "#754cbc", linewidth = 1.5, lineend = "round", linejoin = "round") +
  annotate(geom = "segment", alpha = 0, x = 0,  y = 31250, xend = -0.25, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  theme_tufte(base_size = 22)
```
:::

:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}
::: {style="color: #1b8883; text-align: center"}
Draw a scatterplot
:::

::: {style="color: #a68100; text-align: center"}
Use a line to describe the<br>pattern of points
:::

```{r}
#| echo: false

educ_income |> gt() |> 
  cols_align(align = "center", columns = everything()) |> # center columns
  tab_options(table.background.color = "#e8e3d3", table.font.size = px(16L)) |>
  opt_table_outline(color = "#85754d") # outline table with colored border
```


:::
  
::: {.column width="60%"}

::: {style="color: #e8e3d3; text-align: center; font-size: 1.5em"}
Can use this line to predict the level of income for a person with any level of education <br> *(within the range that we observe)*
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

deterministic_plot <- ggplot(educ_income, aes(x = Education, y = Income)) + 
  labs(x = "Education (in years)") +
  geom_point(color = "#1b8883", size = 4, alpha = 0.75) +
  annotate(geom = "segment", x = 0, xend = 20, y = 5000, yend = 40000, color = "#a68100", alpha = 0.75, linewidth = 2) +
  annotate(geom = "segment", alpha = 0, x = 9, y = 0, yend = 20750, linetype = 2, color = "#754cbc", linewidth = 1.5) + # dashed line
  annotate(geom = "segment", alpha = 0, x = 9,  y = 20250, yend = 20750, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  annotate(geom = "segment", alpha = 0, x = 9, y = 20750, xend = 0, linetype = 2, color = "#754cbc", linewidth = 1.5, lineend = "round", linejoin = "round") +
  annotate(geom = "segment", alpha = 0, x = 0,  y = 20750, xend = -0.25, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  annotate(geom = "segment", alpha = 0, x = 15, y = 0, yend = 31250, linetype = 2, color = "#754cbc", linewidth = 1.5, lineend = "round", linejoin = "round") +
  annotate(geom = "segment", alpha = 0, x = 15,  y = 30750, yend = 31250, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  annotate(geom = "segment", alpha = 0, x = 15, y = 31250, xend = 0, linetype = 2, color = "#754cbc", linewidth = 1.5, lineend = "round", linejoin = "round") +
  annotate(geom = "segment", alpha = 0, x = 0,  y = 31250, xend = -0.25, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  theme_tufte(base_size = 22)
deterministic_plot
```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}
::: {style="color: #1b8883; text-align: center"}
Draw a scatterplot
:::

::: {style="color: #a68100; text-align: center"}
Use a line to describe the<br>pattern of points
:::

```{r}
#| echo: false

educ_income |> gt() |> 
  cols_align(align = "center", columns = everything()) |> # center columns
  tab_options(table.background.color = "#e8e3d3", table.font.size = px(16L)) |>
  opt_table_outline(color = "#85754d") # outline table with colored border
```


:::
  
::: {.column width="60%"}

::: {style="color: #754cbc; text-align: center; font-size: 1.5em"}
Can use this line to predict the level of income for a person with any level of education <br> [*(within the range that we observe)*]{.fragment fragment-index=4 style="color: #e93cac"}
:::


```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

ggplot(educ_income, aes(x = Education, y = Income)) + 
  labs(x = "Education (in years)") +
  geom_point(color = "#1b8883", size = 4, alpha = 0.75) +
  annotate(geom = "segment", x = 0, xend = 20, y = 5000, yend = 40000, color = "#a68100", alpha = 0.75, linewidth = 2) +
  annotate(geom = "segment", x = 9, y = 0, yend = 20750, linetype = 2, color = "#754cbc", linewidth = 1.5) + # dashed line
  annotate(geom = "segment", x = 9,  y = 20250, yend = 20750, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  annotate(geom = "segment", x = 9, y = 20750, xend = 0, linetype = 2, color = "#754cbc", linewidth = 1.5, lineend = "round", linejoin = "round") +
  annotate(geom = "segment", x = 0,  y = 20750, xend = -0.25, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  annotate(geom = "segment", x = 15, y = 0, yend = 31250, linetype = 2, color = "#754cbc", linewidth = 1.5, lineend = "round", linejoin = "round") +
  annotate(geom = "segment", x = 15,  y = 30750, yend = 31250, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  annotate(geom = "segment", x = 15, y = 31250, xend = 0, linetype = 2, color = "#754cbc", linewidth = 1.5, lineend = "round", linejoin = "round") +
  annotate(geom = "segment", x = 0,  y = 31250, xend = -0.25, linetype = 1, color = "#754cbc", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  theme_tufte(base_size = 22) 

```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 2em"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

deterministic_plot
```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 2em"}
[$\widehat{y}$]{style="color: #a68100"} $=$ $a$ $+$ $b$$x$
:::

::: {style="color: #a68100; text-align: center; font-size: 1em"}
$\widehat{y}$ is the predicted value of $Y$ <br> (the dependent variable)
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

deterministic_plot
```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 2em"}
[$\widehat{y}$]{style="color: #a68100"} $=$ $a$ $+$ $b$[$x$]{style="color: #1b8883"}
:::

::: {style="color: #a68100; text-align: center; font-size: 1em"}
$\widehat{y}$ is the predicted value of $Y$ <br> (the dependent variable)
:::

::: {style="color: #1b8883; text-align: center; font-size: 1em"}
$x$ is the value of $X$ <br> for the individual
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

deterministic_plot
```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 2em"}
[$\widehat{y}$]{style="color: #a68100"} $=$ $a$ $+$ [$b$]{style="color: #e93cac"}[$x$]{style="color: #1b8883"}
:::

::: {style="color: #a68100; text-align: center; font-size: 1em"}
$\widehat{y}$ is the predicted value of $Y$ <br> (the dependent variable)
:::

::: {style="color: #1b8883; text-align: center; font-size: 1em"}
$x$ is the value of $X$ <br> for the individual
:::

::: {style="color: #e93cac; text-align: center; font-size: 1em"}
$b = \text{slope of the line}$ <br> (i.e. how much $Y$ changes with each one-unit difference in $X$)
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

deterministic_plot
```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 2em"}
[$\widehat{y}$]{style="color: #a68100"} $=$ [$a$]{style="color: #754cbc"} $+$ [$b$]{style="color: #e93cac"}[$x$]{style="color: #1b8883"}
:::

::: {style="color: #a68100; text-align: center; font-size: 1em"}
$\widehat{y}$ is the predicted value of $Y$ <br> (the dependent variable)
:::

::: {style="color: #1b8883; text-align: center; font-size: 1em"}
$x$ is the value of $X$ <br> for the individual
:::

::: {style="color: #e93cac; text-align: center; font-size: 1em"}
$b = \text{slope of the line}$ <br> (i.e. how much $Y$ changes with each one-unit difference in $X$)
:::

::: {style="color: #754cbc; text-align: center; font-size: 1em"}
$a = \text{Y-intercept}$ <br> (the predicted value of $Y$ when $X = 0$; a.k.a. the constant)
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

deterministic_plot
```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 2em"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>
<br>
<br>
<br>


::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ $5000$ $+$ $1750$$x$
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

deterministic_plot
```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 2em"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>
<br>
<br>
<br>


::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ [$5000$]{style="color: #754cbc"} $+$ $1750$$x$
:::

<br>

::: {style="color: #754cbc; text-align: center; font-size: 1em"}
A person with $0$ years of education is predicted to make $\$5,000$
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

deterministic_plot + geom_point(aes(x = 0, y = 5000), shape = 21, color = "#754cbc", size = 15, stroke = 2)
```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 2em"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>
<br>
<br>
<br>


::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ [$5000$]{style="color: #754cbc"} $+$ [$1750$]{style="color: #e93cac"}$x$
:::

<br>

::: {style="color: #754cbc; text-align: center; font-size: 1em"}
A person with $0$ years of education is predicted to make $\$5,000$
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

deterministic_plot + 
  annotate(geom = "point", x = 0, y = 5000, shape = 21, color = "#754cbc", size = 15, stroke = 2) +
  annotate(geom = "segment", x = 4, y = 12000, xend = 5, linetype = 1, color = "#e93cac", linewidth = 1, lineend = "square") +
  annotate(geom = "segment", x = 5, y = 12000, yend = 13750, linetype = 1, color = "#e93cac", linewidth = 1, lineend = "square")
  
```


:::
  
::::

::: {style="color: #e93cac; text-align: center; font-size: 1em; width: 500px; position: absolute; bottom: 85px; right: -75px"}
Income is predicted to increase by $\$1,750$ for each additional year of education
:::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ $5000$ $+$ $1750$$x$
:::

<br>

::: {style="font-size: 1em; text-align: center"}
> [**Deterministic association:**]{.underline style="font-size: 2em; color: #e93cac"} <br> <br>
All of the points in the scatterplot fall on the line. <br><br>
[Perfectly predict<br>$Y$ based on $X$.]{.fragment} <br><br>
[$|r| = 1.0$]{.fragment}
:::

<br>



:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

deterministic_plot
  
```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>

::: {style="font-size: 1em; text-align: center"}
> [**Non-deterministic association:**]{.underline style="font-size: 1.5em; color: #e93cac"} <br> <br>
Points in the scatterplot do not all fall on the line <br><br>
[Cannot perfectly predict $Y$ based on $X$.]{.fragment} <br><br>
[$|r| \lt 1.0$]{.fragment}
:::

<br>



:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

#library(faux)
# simulating data --> know what the values of the x are, determining values of y in kyle's visual that align with desired mean, sd, and r
# for(i in 100000:200000){
#   set.seed(i)
#   educ_income2 <- tibble(Education = c(2, 8, 11, 12, 13, 14, 15, 16, 16, 16, 17, 20),
#                        Income = sample(x = seq(from = 10000, to = 37000, by = 250), prob = dnorm(seq(from = 10000, to = 37000, by = 250), mean = 22916.67, sd = 8784.887), size = 12, replace = TRUE))
#   
#   if(near(cor(educ_income2)[1, 2], 0.853, tol = 0.001))
#     print(paste("seed", i, ":", cor(educ_income2)[1, 2]))
# }

educ_income2 <- tibble(Education = c(2, 8, 11, 12, 13, 14, 15, 16, 16, 16, 17, 20),
                       Income = c(10500, 10000, 17000, 20000, 19500, 17000, 21050, 25000, 30000, 35000, 32250, 34000))
# cor(educ_income2)
# plot(educ_income2)
# lm(data = educ_income2, formula = Income ~ Education) |> summary()

non_deterministic_plot <- ggplot(educ_income2, aes(x = Education, y = Income)) + 
  labs(x = "Education (in years)") +
  geom_point(color = "#1b8883", size = 4) +
  theme_tufte(base_size = 22) + coord_cartesian(xlim = c(-0.25, 20), ylim = c(-0.5, 40000))

non_deterministic_plot
```

:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>

::: {style="font-size: 1em; text-align: center"}
> [**Non-deterministic association:**]{.underline style="font-size: 1.5em; color: #e93cac"} <br>
:::

<br>

::: {style="font-size: 1em; text-align: center"}
A lot of different lines appear to characterize the points
:::

<br>

::: {.fragment style="font-size: 1em; text-align: center"}
Each line comes close to some points but misses others by a lot.
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot +
  geom_abline(intercept = 6000, slope = 1200, color = "#6e8e13", linewidth = 1.5) +
  geom_abline(intercept = 1000, slope = 1800, color = "#e93cac", linewidth = 1.5) +
  geom_abline(intercept = -3000, slope = 1700, color = "#a68100", linewidth = 1.5) +
  geom_abline(intercept = 2000, slope = 1500, color = "#2ad2c9", linewidth = 1.5) +
  geom_abline(intercept = 10000, slope = 700, color = "#754cbc", linewidth = 1.5) +
  geom_abline(intercept = -12000, slope = 2500, color = "darkslategrey", linewidth = 1.5) +
  theme_tufte(base_size = 22) + coord_cartesian(xlim = c(-0.25, 20), ylim = c(-0.5, 40000)) +
  transition_layers(layer_length = 1, transition_length = 1, keep_layers = TRUE, from_blank = FALSE)

```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>

::: {style="font-size: 1em; text-align: center"}
Want the line that fits the data best - i.e. comes as close as possible, on average, to all points
:::

<br>

::: {.fragment style="font-size: 1em; text-align: center"}
Technically: Want the line that minimizes the **(squared) errors** we would make in **predicting** $Y$ with the line
:::

<br>

::: {.fragment style="font-size: 1em; text-align: center"}
Looking for the [least squares]{.underline} regression line
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Describe the line to describe the association and predict values of the dependent variable <br> [Blah]{style="color: #e8e3d3"}
:::

 
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot +
  geom_abline(intercept = 6000, slope = 1200, color = "#6e8e13", linewidth = 1.5) +
  geom_abline(intercept = 1000, slope = 1800, color = "#e93cac", linewidth = 1.5) +
  geom_abline(intercept = -3000, slope = 1700, color = "#a68100", linewidth = 1.5) +
  geom_abline(intercept = 2000, slope = 1500, color = "#2ad2c9", linewidth = 1.5) +
  geom_abline(intercept = 10000, slope = 700, color = "#754cbc", linewidth = 1.5) +
  geom_abline(intercept = -12000, slope = 2500, color = "darkslategrey", linewidth = 1.5) +
  theme_tufte(base_size = 22) + coord_cartesian(xlim = c(-0.25, 20), ylim = c(-0.5, 40000)) 

```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>

::: {style="font-size: 1em; text-align: center"}
Want the line that fits the data best - i.e. comes as close as possible, on average, to all points
:::

<br>

::: {style="font-size: 1.25em; text-align: center"}
Need two components of the regression line: 

1. [$a$ (y-intercept)]{style="color: #754cbc"}
2. [$b$ (slope)]{style="color: #e93cac"}
:::

:::
  
::: {.column width="60%"}

::: {.fragment fragment-index=1 style="color: black; text-align: center; font-size: 1.5em"}
Calculating the least squares regression line
:::

::: {.fragment fragment-index=1 style="color: #e93cac; border: 3px solid #e93cac; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center;"}
Step 1: calculate the slope
:::

::: {.fragment fragment-index=2 style="color: black; text-align: center; font-size: 2em"}
$$\begin{aligned}
\color{#e93cac}{b} = {r}(\frac{{s_y}}{{s_x}})
\end{aligned}$$
:::

:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>

::: {style="font-size: 1em; text-align: center"}
Want the line that fits the data best - i.e. comes as close as possible, on average, to all points
:::

<br>

::: {style="font-size: 1.25em; text-align: center"}
Need two components of the regression line: 

1. [$a$ (y-intercept)]{style="color: #754cbc"}
2. [$b$ (slope)]{style="color: #e93cac"}
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Calculating the least squares regression line
:::

::: {style="color: #e93cac; border: 3px solid #e93cac; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center;"}
Step 1: calculate the slope
:::

::: {style="color: black; text-align: center; font-size: 2em"}
$$\begin{aligned}
\color{#e93cac}{b} = \color{#a68100}{r}(\frac{{s_y}}{{s_x}})
\end{aligned}$$
:::

::: {style="color: #a68100; font-size: 1em; text-align: center;"}
Correlation coefficient
:::

:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>

::: {style="font-size: 1em; text-align: center"}
Want the line that fits the data best - i.e. comes as close as possible, on average, to all points
:::

<br>

::: {style="font-size: 1.25em; text-align: center"}
Need two components of the regression line: 

1. [$a$ (y-intercept)]{style="color: #754cbc"}
2. [$b$ (slope)]{style="color: #e93cac"}
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Calculating the least squares regression line
:::

::: {style="color: #e93cac; border: 3px solid #e93cac; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center;"}
Step 1: calculate the slope
:::

::: {style="color: black; text-align: center; font-size: 2em"}
$$\begin{aligned}
\color{#e93cac}{b} = \color{#a68100}{r}(\frac{\color{#6e8e13}{s_y}}{{s_x}})
\end{aligned}$$
:::

::: {style="color: #a68100; font-size: 1em; text-align: center;"}
Correlation coefficient
:::

::: {style="color: #6e8e13; font-size: 1em; text-align: center;"}
Standard deviation of<br>the dependent variable
:::

:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>

::: {style="font-size: 1em; text-align: center"}
Want the line that fits the data best - i.e. comes as close as possible, on average, to all points
:::

<br>

::: {style="font-size: 1.25em; text-align: center"}
Need two components of the regression line: 

1. [$a$ (y-intercept)]{style="color: #754cbc"}
2. [$b$ (slope)]{style="color: #e93cac"}
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Calculating the least squares regression line
:::

::: {style="color: #e93cac; border: 3px solid #e93cac; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center;"}
Step 1: calculate the slope
:::

::: {style="color: black; text-align: center; font-size: 2em"}
$$\begin{aligned}
\color{#e93cac}{b} = \color{#a68100}{r}(\frac{\color{#6e8e13}{s_y}}{\color{#1b8883}{s_x}})
\end{aligned}$$
:::

::: {style="color: #a68100; font-size: 1em; text-align: center;"}
Correlation coefficient
:::

::: {style="color: #6e8e13; font-size: 1em; text-align: center;"}
Standard deviation of<br>the dependent variable
:::

::: {style="color: #1b8883; font-size: 1em; text-align: center;"}
Standard deviation of<br>the independent variable
:::

:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.85em;"}
$\widehat{y}$ $=$ $a$ $+$ $b$$x$
:::

<br>

::: {style="font-size: 1em; text-align: center"}
Want the line that fits the data best - i.e. comes as close as possible, on average, to all points
:::

<br>

::: {style="font-size: 1.25em; text-align: center"}
Need two components of the regression line: 

1. [$a$ (y-intercept)]{style="color: #754cbc"}
2. [$b$ (slope)]{style="color: #e93cac"}
:::

:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
Calculating the least squares regression line
:::

::: {style="color: #754cbc; border: 3px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center;"}
Step 2: calculate the Y-intercept
:::

::: {style="color: black; text-align: center; font-size: 2em"}
$$\begin{aligned}
\color{#754cbc}{a} = \color{#6e8e13}{\bar{y}}-\color{#e93cac}{b}\color{#1b8883}{\bar{x}}
\end{aligned}$$
:::

::: {style="color: #6e8e13; font-size: 1em; text-align: center;"}
Mean of the<br>dependent variable
:::

::: {style="color: #e93cac; font-size: 1em; text-align: center;"}
Slope
:::

::: {style="color: #1b8883; font-size: 1em; text-align: center;"}
Mean of the<br>independent variable
:::

:::
  
::::


## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="color: #e93cac; border: 3px solid #e93cac; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center;"}
Step 1: calculate the slope
:::

<br>

::: {.fragment style="font-size: 1.75em;"}
$$\begin{aligned} \color{#e93cac}b &= r(\frac{s_y}{s_x}) \\ &= 0.857(\frac{8655.131}{4.735}) \\ &= \color{#e93cac}{1566.515} \end{aligned}$$
:::

::: {.fragment style="font-size: 1.25em; text-align: center;"}
Income increases by $\color{#e93cac}{\$1,566.52}$ for each additional year of education
:::


:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
$\bar{y} =$ `r round(mean(educ_income2$Income), 3)` &emsp; &emsp; &emsp; $\bar{x} =$ `r round(mean(educ_income2$Education), 3)` <br>
$s_y =$ `r round(sd(educ_income2$Income), 3)` &emsp; &emsp; &emsp; $s_x =$ `r round(sd(educ_income2$Education), 3)` <br>
$r =$ `r round(cor(educ_income2)[1,2], 3)` 
:::

<br>


```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot +
  theme_tufte(base_size = 22) + coord_cartesian(xlim = c(-0.25, 20), ylim = c(-0.5, 40000)) 

```


:::
  
::::

## Bivariate Regression

:::: {.columns}

::: {.column width="40%"}

::: {style="color: #754cbc; border: 3px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center;"}
Step 2: calculate the Y-intercept
:::

<br>

::: {.fragment style="font-size: 1.75em; position: absolute; left: 0px; background: #e8e3d3;"}
$$\begin{aligned} \color{#754cbc}a &= \bar{y} - b\bar{x} \\ &= 22608.333 - (1566.515)(13.333) \\ &= \color{#754cbc}{1721.989} \end{aligned}$$
:::

::: {.fragment style="font-size: 1.25em; text-align: center; position: absolute; bottom: 25px"}
A person with $0$ years of<br>education is predicted to<br>make $\color{#754cbc}{\$1721.99}$. 
:::


:::
  
::: {.column width="60%"}

::: {style="color: black; text-align: center; font-size: 1.5em"}
$\bar{y} =$ `r round(mean(educ_income2$Income), 3)` &emsp; &emsp; &emsp; $\bar{x} =$ `r round(mean(educ_income2$Education), 3)` <br>
$s_y =$ `r round(sd(educ_income2$Income), 3)` &emsp; &emsp; &emsp; $s_x =$ `r round(sd(educ_income2$Education), 3)` <br>
$r =$ `r round(cor(educ_income2)[1,2], 3)` 
:::

<br>


```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot +
  theme_tufte(base_size = 22) + coord_cartesian(xlim = c(-0.25, 20), ylim = c(-0.5, 40000)) 

```


:::
  
::::

## Bivariate Regression

::: {.center style="color: black; border: 3px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center; width: 800px"}
Ordinary least squares regression line: [$\widehat{y} = a + bx$]{style="font-size: 1.5em; color: white; background: black"}
:::

::: {.center style="background: black; color: white; border: 3px solid #e8e3d3; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center; width: 600px"}
$\widehat{\text{Income}} = 1721.989 + 1566.515(\text{Education})$
:::

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="color: #a68100; border: 3px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center;"}
This is the line that fits the data best - i.e., comes as close as possible, on average, to all points.
:::

::: {.fragment style="font-size: 1em; position: absolute; left: 0px; bottom: -10px; background: #e8e3d3; width: 450px; text-align: center"}
*Technically: The line that minimizes the (squared) errors we would make in predicting Y with the line*
:::


:::
  
::: {.column width="60%"}


::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot +
  geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75) + 
  theme_tufte(base_size = 22) + coord_cartesian(xlim = c(-0.25, 20), ylim = c(-0.5, 40000)) 

```
:::

:::
  
::::

## Bivariate Regression

::: {.center style="color: black; border: 3px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center; width: 800px"}
Ordinary least squares regression line: [$\widehat{y} = a + bx$]{style="font-size: 1.5em; color: white; background: black"}
:::

::: {.center style="background: black; color: white; border: 3px solid #e8e3d3; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center; width: 600px"}
$\widehat{\text{Income}} = 1721.989 + 1566.515(\text{Education})$
:::

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="font-size: 1.25em; text-align: center;"}
Can use this line to predict values of Y (income) for any value of X (education)
:::

::: {.fragment style="font-size: 1em; text-align: center; color: #e93cac"}
Example: What is the predicted level of income for a person with 14 years of education?
:::

:::
  
::: {.column width="60%"}


::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot +
  geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75) + 
  theme_tufte(base_size = 22) + coord_cartesian(xlim = c(-0.25, 20), ylim = c(-0.5, 40000)) 

```
:::

:::
  
::::

## Bivariate Regression

::: {.center style="color: black; border: 3px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center; width: 800px"}
Ordinary least squares regression line: [$\widehat{y} = a + bx$]{style="font-size: 1.5em; color: white; background: black"}
:::

::: {.center style="background: black; color: white; border: 3px solid #e8e3d3; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center; width: 600px"}
$\widehat{\text{Income}} = 1721.989 + 1566.515(\text{Education})$
:::

:::: {.columns}

::: {.column width="40%"}

<br>

::: {style="font-size: 1.25em; text-align: center;"}
Can use this line to predict values of Y (income) for any value of X (education)
:::

::: {style="font-size: 1em; text-align: center; color: #e93cac"}
Example: What is the predicted level of income for a person with 14 years of education?
:::

::: {style="background: #e93cac; color: white; border: 3px solid #690c48; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center; position: absolute; bottom: 0px; left: -50px"}
$\begin{aligned} \widehat{\text{Income}} &= 1721.989 + 1566.515(14) \\ &= 23653.20 \end{aligned}$
:::

:::
  
::: {.column width="60%"}


::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot + geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75) + 
  annotate(geom = "segment", x = 14, y = 0, yend = 23653.20, linetype = 2, color = "#e93cac", linewidth = 1.5) + # dashed line
  annotate(geom = "segment", x = 14,  y = 23153.2, yend = 23653.20, linetype = 1, color = "#e93cac", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  annotate(geom = "segment", x = 14, y = 23653.20, xend = 0, linetype = 2, color = "#e93cac", linewidth = 1.5) + # dashed line
  annotate(geom = "segment", x = 0,  y = 23653.20, xend = -0.25, linetype = 1, color = "#e93cac", lineend = "round", linejoin = "round", arrow = arrow(type = "closed", length = unit(6,"mm"))) + # arrowhead (without dashed line outline)
  theme_tufte(base_size = 22) + coord_cartesian(xlim = c(-0.25, 20), ylim = c(-0.5, 40000)) 

```
:::

:::
  
::::


# How well does the best fitting line [**fit**]{.underline} the data?

## Coefficient of Determination

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px;  font-size: 1.25em; text-align: center; width: 550px"}
Assessing the fit of the regression line
:::

::: {style="background: black; color: white; border: 3px solid #e8e3d3; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center; width: 600px"}
$\widehat{\text{Income}} = 1721.989 + 1566.515(\text{Education})$
:::

:::: {.columns}

::: {.column width="40%"}

<br>

::: {.fragment style="color: #a68100; border: 3px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center;"}
This is the line that fits the data best - i.e., comes as close as possible, on average, to all points.
:::

<br>

::: {.fragment style="font-size: 1em; text-align: center; color: #e93cac"}
**BUT STILL DOES NOT “FIT” <br> THE DATA PERFECTLY** <br>
*(misses some points)*

:::

:::
  
::: {.column width="60%"}


::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot + 
  geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75)

```
:::

:::
  
::::

## Coefficient of Determination

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px;  font-size: 1.25em; text-align: center; width: 550px"}
Assessing the fit of the regression line
:::

::: {style="background: black; color: white; border: 3px solid #e8e3d3; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center; width: 600px"}
$\widehat{\text{Income}} = 1721.989 + 1566.515(\text{Education})$
:::

:::: {.columns}

::: {.column width="40%"}

<br>

::: { style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em; text-align: center; width: 300px; position: absolute; left: 75px"}
Coefficient of determination ($R^2$) measures the level of model fit
:::

::: {.fragment fragment-index=1 style="font-size: 1.25em; text-align: center; position: absolute; bottom: 75px; left: 150px"}
$$
R^2 = (\color{#1b8883}{r})(\color{#1b8883}{r})
$$
:::

::: {.fragment fragment-index=1 style="font-size: 1em; text-align: center; color: #1b8883; position: absolute; bottom: 0px; left: 100px"}
Simply square the<br>correlation coefficient
:::

:::
  
::: {.column width="60%"}

::: {.fragment fragment-index=2 style="font-size: 1em; text-align: center; color: #754cbc; position: absolute; top: 75px; right: 0px; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px;"}
[Range of $R^2$:]{.underline} <br>   
$0.0 =$ no association, <br> 
no predictive value of knowing X <br>
$1.0 =$ deterministic
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot + 
  geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75)

```
:::

:::
  
::::

---

### Interpretation of the Coefficient of Determination

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 1.5em; text-align: center;"}
$$
R^2 = (r)(r)
$$
:::
:::
  
::: {.column width="60%"}

::: {style="background: #c5b4e3; font-size: 1.25em; text-align: center; color: #754cbc; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; width: 325px; position: absolute; right: 0px"}
**INTERPRETATION #1**
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot + 
  geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75)

```
:::

:::
  
::::

---

### Interpretation of the Coefficient of Determination

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 1.5em; text-align: center;"}
$$
R^2 = (r)(r)
$$
:::

<br>

::: {style="border: 4px solid #690c48; border-radius: 15px; font-size: 1em; text-align: center; border-radius: 15px; padding: 5px 5px 5px 5px;"}
In the absence of any other information, we would just guess the **mean** for the income of any individual
*(since the mean is the balancing point of the distribution)*
:::

:::
  
::: {.column width="60%"}

::: {style="background: #c5b4e3; font-size: 1.25em; text-align: center; color: #754cbc; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; width: 325px; position: absolute; right: 0px"}
**INTERPRETATION #1**
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot + 
  geom_hline(yintercept = mean(educ_income2$Income), color = "#690c48", alpha = 0.75, linewidth = 1.5) + 
  annotate(geom = "text", label = expression(hat(p) == 22608.33), parse = TRUE, x = 5, y = 28000, size = 7, color = "#690c48", alpha = 0.75)

```
:::

:::
  
::::

---

### Interpretation of the Coefficient of Determination

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 1.5em; text-align: center;"}
$$
R^2 = (r)(r)
$$
:::

<br>

::: {style="border: 4px solid #690c48; border-radius: 15px; font-size: 1em; text-align: center; border-radius: 15px; padding: 5px 5px 5px 5px;"}
In the absence of any other information, we would just guess the **mean** for the income of any individual 
*(since the mean is the balancing point of the distribution)*
:::

<br>

::: {style="background: #e93cac; border: 4px solid #690c48; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
For almost all cases there would be ERROR in these predictions <br>
$y \ne \bar{y}$
:::

:::
  
::: {.column width="60%"}

::: {style="background: #c5b4e3; font-size: 1.25em; text-align: center; color: #754cbc; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; width: 325px; position: absolute; right: 0px"}
**INTERPRETATION #1**
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot + 
  annotate(geom = "text", label = expression(hat(p) == 22608.33), parse = TRUE, x = 5, y = 28000, size = 7, color = "#690c48", alpha = 0.75) + 
  #geom_segment(data = educ_income2, aes(x = Education, y = Income, yend = yhat))
  geom_segment(aes(yend = mean(Income)), color = "#e93cac", linewidth = 1.5) + 
  geom_hline(yintercept = mean(educ_income2$Income), color = "#690c48", alpha = 0.75, linewidth = 1.5) + 
  geom_point(color = "#1b8883", size = 4)

```
:::

:::
  
::::

---

### Interpretation of the Coefficient of Determination

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 1.5em; text-align: center;"}
$$
R^2 = (r)(r)
$$
:::

<br>

::: {data-id="box4" style="border: 4px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
If we know individuals’ level of education, we would use this information to predict individual income
*(regression line represents the best prediction line for the association between education and income)*
:::

:::
  
::: {.column width="60%"}

::: {style="background: #c5b4e3; font-size: 1.25em; text-align: center; color: #754cbc; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; width: 325px; position: absolute; right: 0px"}
**INTERPRETATION #1**
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot + 
  geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75)

```
:::

:::
  
::::

---

### Interpretation of the Coefficient of Determination

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 1.5em; text-align: center;"}
$$
R^2 = (r)(r)
$$
:::

<br>

::: {data-id="box4" style="border: 4px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
If we know individuals’ level of education, we would use this information to predict individual income
*(regression line represents the best prediction line for the association between education and income)*
:::

<br>

::: {style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
For almost all cases there would be ERROR in these predictions <br>
$y \ne \widehat{y}$
:::

:::
  
::: {.column width="60%"}

::: {style="background: #c5b4e3; font-size: 1.25em; text-align: center; color: #754cbc; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; width: 325px; position: absolute; right: 0px"}
**INTERPRETATION #1**
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

educ_income2 <- educ_income2 |> mutate(yhat = 1721.989 + (1566.515 * Education))

non_deterministic_plot + 
  geom_segment(data = educ_income2, aes(x = Education, y = Income, yend = yhat), color = "#ffc700", linewidth = 1.5) +
  geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75) + 
  geom_point(color = "#1b8883", size = 4)


```
:::

:::
  
::::

---

### Interpretation of the Coefficient of Determination

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 1.5em; text-align: center;"}
$$
R^2 = (r)(r)
$$
:::

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
**QUESTION**: <br>
How much better do we do in predicting the dependent variable using the regression line versus just guessing the mean value?
:::

::: {.fragment style="font-size: 1.5em; text-align: center; position: absolute; bottom: 0px"}
$\begin{aligned}r &= 0.857 \\ R^2 &= (r)(r) \\ &= (0.857)(0.857) \\&= 0.734 \end{aligned}$
:::


:::
  
::: {.column width="60%"}

::: {style="background: #c5b4e3; font-size: 1.25em; text-align: center; color: #754cbc; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; width: 325px; position: absolute; right: 0px"}
**INTERPRETATION #1**
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

plot1 <- non_deterministic_plot + 
  geom_hline(yintercept = mean(educ_income2$Income), color = "#690c48", alpha = 0.75, linewidth = 1.5) +
  geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75) + 
  geom_segment(aes(yend = mean(Income)), color = "#e93cac", linewidth = 1.5, lineend = "butt") + 
  #geom_hline(yintercept = mean(educ_income2$Income), color = "#e93cac", alpha = 0.75, linewidth = 1.5) +
  annotate(geom = "text", label = "versus", y = 30000, x = 7, color = "#754cbc", size = 15) +
  geom_segment(data = educ_income2, aes(x = Education, y = Income, yend = yhat), color = "#ffc700", linewidth = 1.5, alpha = 0.75, lineend = "butt") +
  #geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75) + 
  #geom_point(color = "#1b8883", size = 4) + 
  transition_layers(from_blank = FALSE, keep_layers = c(Inf, Inf, Inf, 0, 0, Inf), layer_length = 1, transition_length = 2)

animate(plot1, nframes = 100, duration = 15, end_pause = 50)

```
:::

:::
  
::::

---

### Interpretation of the Coefficient of Determination

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 1.5em; text-align: center;"}
$$
R^2 = (r)(r)
$$
:::

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
If we are predicting individuals’ income, we will reduce our errors of prediction by about 73% if we take into consideration how much education these individuals have.
:::

::: {style="font-size: 1.5em; text-align: center; position: absolute; bottom: 0px"}
$\begin{aligned}r &= 0.857 \\ R^2 &= (r)(r) \\ &= (0.857)(0.857) \\&= 0.734 \end{aligned}$
:::

:::
  
::: {.column width="60%"}

::: {style="background: #c5b4e3; font-size: 1.25em; text-align: center; color: #754cbc; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; width: 325px; position: absolute; right: 0px"}
**INTERPRETATION #1**
:::

::: {.fragment style="background: #c5b4e3; font-size: 1em; text-align: center; color: #754cbc; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; width: 500px; position: absolute; right: 0px; top: 160px"}
The proportional reduction of prediction error achieved by using the linear regression equation to predict the values of the dependent variable (Y)
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot + 
  geom_segment(aes(yend = mean(Income)), color = "#e93cac", linewidth = 1.5) + 
  geom_hline(yintercept = mean(educ_income2$Income), color = "#690c48", alpha = 0.75, linewidth = 1.5) +
  geom_segment(data = educ_income2, aes(x = Education, y = Income, yend = yhat), color = "#ffc700", linewidth = 1.5) +
  geom_abline(intercept = 1721.989, slope = 1566.515, color = "#a68100", linewidth = 1.5, alpha = 0.75) + 
  geom_point(color = "#1b8883", size = 4)


```
:::

:::


  
::::

---

### Interpretation of the Coefficient of Determination

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 1.5em; text-align: center;"}
$$
R^2 = (r)(r)
$$
:::



:::
  
::: {.column width="60%"}

::: {style="background: #aadb1e; border: 4px solid #6e8e13; font-size: 1.25em; text-align: center; color: #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; width: 325px; position: absolute; right: 0px"}
**INTERPRETATION #2**
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot 


```
:::

:::
  
::::

---

### Interpretation of the Coefficient of Determination

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 1.5em; text-align: center;"}
$$
R^2 = (r)(r)
$$
:::

::: {.fragment fragment-index=1 style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
**QUESTION**: <br> How much of this variation is due to the fact that people have different levels of education?
:::

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
Income varies!
:::


::: {.fragment fragment-index=2 style="font-size: 1.5em; text-align: center; position: absolute; bottom: 0px"}
$\begin{aligned}r &= 0.857 \\ R^2 &= (r)(r) \\ &= (0.857)(0.857) \\&= 0.734 \end{aligned}$
:::


:::
  
::: {.column width="60%"}

::: {style="background: #aadb1e; border: 4px solid #6e8e13; font-size: 1.25em; text-align: center; color: #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; width: 325px; position: absolute; right: 0px"}
**INTERPRETATION #2**
:::

::: {.fragment style="background: #aadb1e; border: 4px solid #6e8e13; font-size: 1em; text-align: center; color: #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; width: 500px; position: absolute; right: 0px; top: 160px"}
The proportion of the variance in the dependent variable ($Y$) explained by the independent variable ($X$)
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot + 
  annotate(geom = "segment", x = 0, y = 10000, yend = 35000, color = "#2ad2c9", linewidth = 1.5) + 
  annotate(geom = "segment", x = -0.75, y = 10000, xend = 0.75, color = "#2ad2c9", linewidth = 1.5) + 
  annotate(geom = "segment", x = -0.75, y = 35000, xend = 0.75, color = "#2ad2c9", linewidth = 1.5)


```
:::

:::
  
::::

---

### Interpretation of the Coefficient of Determination

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 1.5em; text-align: center;"}
$$
R^2 = (r)(r)
$$
:::

::: {style="border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
About $73\%$ of the variation in income is explained by the diversity of education levels in the sample.
:::

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
Income varies!
:::


::: {style="font-size: 1.5em; text-align: center; position: absolute; bottom: 0px"}
$\begin{aligned}r &= 0.857 \\ R^2 &= (r)(r) \\ &= (0.857)(0.857) \\&= 0.734 \end{aligned}$
:::


:::
  
::: {.column width="60%"}

::: {style="background: #aadb1e; border: 4px solid #6e8e13; font-size: 1.25em; text-align: center; color: #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; width: 325px; position: absolute; right: 0px"}
**INTERPRETATION #2**
:::

::: {style="background: #aadb1e; border: 4px solid #6e8e13; font-size: 1em; text-align: center; color: #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; width: 500px; position: absolute; right: 0px; top: 160px"}
The proportion of the variance in the dependent variable ($Y$) explained by the independent variable ($X$)
:::

::: {style="position: absolute; bottom: 3px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

non_deterministic_plot + 
  annotate(geom = "segment", x = 0, y = 10000, yend = 35000, color = "#2ad2c9", linewidth = 1.5) + 
  annotate(geom = "segment", x = -0.75, y = 10000, xend = 0.75, color = "#2ad2c9", linewidth = 1.5) + 
  annotate(geom = "segment", x = -0.75, y = 35000, xend = 0.75, color = "#2ad2c9", linewidth = 1.5)
```
:::

:::
  
::::

# Break! {.section-title background-color="#2ad2c9"}

# Another Example

---

*A researcher collected the following data on years of education ($X$) and number of children ($Y$) for a sample of married adults and produced the following raw data.*

::: {style="font-size: 0.9em; position: absolute; right: -75px; bottom: 0px; table-layout: fixed; width: 850px"}
|   | Education ($x_i$) | # Kids ($y_i$) | [$x_i -\bar{x}$]{style="color: #e8e3d3"} | [$\frac{x_i-\bar{x}}{s_x}$]{style="color: #e8e3d3"} | [$y_i -\bar{y}$]{style="color: #e8e3d3"} | [$\frac{y_i-\bar{y}}{s_y}$]{style="color: #e8e3d3"} | [$(\frac{x_i-\bar{x}}{s_x})(\frac{y_i-\bar{y}}{s_y})$]{style="color: #e8e3d3"} |
|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
|   | 12 | 2 | [-1.00]{style="color: #e8e3d3"} | [-0.29]{style="color: #e8e3d3"}  | [-0.20]{style="color: #e8e3d3"} | [-0.12]{style="color: #e8e3d3"} | [0.04]{style="color: #e8e3d3"} |
|   | 14 | 1  | [1.00]{style="color: #e8e3d3"} | [0.29]{style="color: #e8e3d3"}  | [-1.20]{style="color: #e8e3d3"}  | [-0.74]{style="color: #e8e3d3"} | [-0.22]{style="color: #e8e3d3"}  |
|   | 17 | 0  | [4.00]{style="color: #e8e3d3"} | [1.18]{style="color: #e8e3d3"} | [-2.20]{style="color: #e8e3d3"} | [-1.36]{style="color: #e8e3d3"} | [-1.60]{style="color: #e8e3d3"} | 
|   | 10 | 3  | [-3.00]{style="color: #e8e3d3"} | [-0.88]{style="color: #e8e3d3"} | [0.80]{style="color: #e8e3d3"} | [0.49]{style="color: #e8e3d3"}  | [-0.44]{style="color: #e8e3d3"}  |
|   | 8 | 5 | [-5.00]{style="color: #e8e3d3"} | [-1.47]{style="color: #e8e3d3"} | [2.80]{style="color: #e8e3d3"} | [1.73]{style="color: #e8e3d3"}  | [-2.54]{style="color: #e8e3d3"}  |
|   | 9 | 3 | [-4.00]{style="color: #e8e3d3"} | [-1.18]{style="color: #e8e3d3"} | [0.80]{style="color: #e8e3d3"} | [0.49]{style="color: #e8e3d3"}  | [-0.58]{style="color: #e8e3d3"}  |
|   | 12 | 4 | [-1.00]{style="color: #e8e3d3"} | [-0.29]{style="color: #e8e3d3"}  | [1.80]{style="color: #e8e3d3"} | [1.11]{style="color: #e8e3d3"}  | [-0.33]{style="color: #e8e3d3"}  |
|   | 14 | 2  | [1.00]{style="color: #e8e3d3"} | [0.29]{style="color: #e8e3d3"}  | [-0.20]{style="color: #e8e3d3"}  | [-0.12]{style="color: #e8e3d3"} | [-0.04]{style="color: #e8e3d3"} |
|   | 18 | 0  | [5.00]{style="color: #e8e3d3"} | [1.47]{style="color: #e8e3d3"}  | [-2.20]{style="color: #e8e3d3"}  | [-1.36]{style="color: #e8e3d3"} | [-2.00]{style="color: #e8e3d3"}  |
|   | 16 | 2  | [3.00]{style="color: #e8e3d3"} | [0.88]{style="color: #e8e3d3"}  | [-0.20]{style="color: #e8e3d3"}  | [-0.12]{style="color: #e8e3d3"} | [-0.11]{style="color: #e8e3d3"}   |
| [**sum**]{style="color: #e8e3d3"} | [130]{style="color: #e8e3d3"} | [22]{style="color: #e8e3d3"} |   |  |  |  |  |  
| [**mean**]{style="color: #e8e3d3"} | [13]{style="color: #e8e3d3"} | [2.2]{style="color: #e8e3d3"} |   |  |  |  |  |  
| [**st. dev.**]{style="color: #e8e3d3"} | [3.399]{style="color: #e8e3d3"} | [1.619]{style="color: #e8e3d3"} |   |  |  |  |  |

: {tbl-colwidths="[12, 17, 13, 11.5, 11.5, 11.5, 11.5, 12]"}
:::

::: {.fragment style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; top: 100px; left: -75px; text-align: center"}
1. Calculate the correlation between education and number of kids
2. Find the OLS regression line for the effect of education on number of kids
3. What is the prediction error for the first person in the data set?
4. Find and interpret the coefficient of determination
:::

---

*A researcher collected the following data on years of education ($X$) and number of children ($Y$) for a sample of married adults and produced the following raw data.*

::: {style="font-size: 0.9em; position: absolute; right: -75px; bottom: 0px; table-layout: fixed; width: 850px"}
|   | Education ($x_i$) | # Kids ($y_i$) | $x_i -\bar{x}$ | $\frac{x_i-\bar{x}}{s_x}$ | $y_i -\bar{y}$ | $\frac{y_i-\bar{y}}{s_y}$ | $(\frac{x_i-\bar{x}}{s_x})(\frac{y_i-\bar{y}}{s_y})$ |
|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
|   | 12 | 2 | -1.00 | -0.29  | -0.20 | -0.12 | 0.04 |
|   | 14 | 1  | 1.00 | 0.29  | -1.20  | -0.74 | -0.22  |
|   | 17 | 0  | 4.00 | 1.18 | -2.20 | -1.36 | -1.60 | 
|   | 10 | 3  | -3.00 | -0.88 | 0.80 | 0.49  | -0.44  |
|   | 8 | 5 | -5.00 | -1.47 | 2.80 | 1.73  | -2.54  |
|   | 9 | 3 | -4.00 | -1.18 | 0.80 | 0.49  | -0.58  |
|   | 12 | 4 | -1.00 | -0.29  | 1.80 | 1.11  | -0.33  |
|   | 14 | 2  | 1.00 | 0.29  | -0.20  | -0.12 | -0.04 |
|   | 18 | 0  | 5.00 | 1.47  | -2.20  | -1.36 | -2.00  |
|   | 16 | 2  | 3.00 | 0.88  | -0.20  | -0.12 | -0.11   |
| **sum** | 130 | 22 |   |  |  |  | -7.81 |  
| **mean** | 13 | 2.2 |   |  |  |  |  |  
| **st. dev.** | 3.399 | 1.619 |   |  |  | [**$r =$**]{.fragment fragment-index=2 style="color: #a68100"}  | [**$-0.868$**]{.fragment fragment-index=2 style="color: #a68100"} |

: {tbl-colwidths="[12, 17, 13, 11.5, 11.5, 11.5, 11.5, 12]"}
:::

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; top: 100px; left: -75px; text-align: center"}
1. Calculate the correlation between education and number of kids
:::

::: {.fragment fragment-index=1 style="background: #e8e3d3; border: 4px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 400px; left: -50px; text-align: center; font-size: 1.25em"}
$$
r = \frac{1}{n-1}\Sigma(\frac{x_i - \bar{x}}{s_x})(\frac{y_i - \bar{y}}{s_y})
$$
:::

---

*A researcher collected the following data on years of education ($X$) and number of children ($Y$) for a sample of married adults and produced the following raw data.*

::: {style="font-size: 0.9em; position: absolute; right: -75px; bottom: 0px; table-layout: fixed; width: 850px"}
|   | Education ($x_i$) | # Kids ($y_i$) | $x_i -\bar{x}$ | $\frac{x_i-\bar{x}}{s_x}$ | $y_i -\bar{y}$ | $\frac{y_i-\bar{y}}{s_y}$ | $(\frac{x_i-\bar{x}}{s_x})(\frac{y_i-\bar{y}}{s_y})$ |
|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
|   | 12 | 2 | -1.00 | -0.29  | -0.20 | -0.12 | 0.04 |
|   | 14 | 1  | 1.00 | 0.29  | -1.20  | -0.74 | -0.22  |
|   | 17 | 0  | 4.00 | 1.18 | -2.20 | -1.36 | -1.60 | 
|   | 10 | 3  | -3.00 | -0.88 | 0.80 | 0.49  | -0.44  |
|   | 8 | 5 | -5.00 | -1.47 | 2.80 | 1.73  | -2.54  |
|   | 9 | 3 | -4.00 | -1.18 | 0.80 | 0.49  | -0.58  |
|   | 12 | 4 | -1.00 | -0.29  | 1.80 | 1.11  | -0.33  |
|   | 14 | 2  | 1.00 | 0.29  | -0.20  | -0.12 | -0.04 |
|   | 18 | 0  | 5.00 | 1.47  | -2.20  | -1.36 | -2.00  |
|   | 16 | 2  | 3.00 | 0.88  | -0.20  | -0.12 | -0.11   |
| **sum** | 130 | 22 |   |  |  |  | -7.81 |  
| **mean** | 13 | 2.2 |   |  |  |  |  |  
| **st. dev.** | [**3.399**]{style="color: #1b8883"} | [**1.619**]{style="color: #6e8e13"} |   |  |  | [**$r =$**]{style="color: #a68100"}  | [**$-0.868$**]{style="color: #a68100"} |

: {tbl-colwidths="[12, 17, 13, 11.5, 11.5, 11.5, 11.5, 12]"}
:::

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; top: 100px; left: -75px; text-align: center"}
2. Find the OLS regression line for the effect of education on number of kids
:::

::: {style="background: #e8e3d3; border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 300px; left: -25px; text-align: center; font-size: 1.25em; width: 200px;"}
$$
\widehat{y} = a + bx
$$
:::

::: {.fragment style="background: #e8e3d3; border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 425px; left: -50px; text-align: center; font-size: 1.25em"}
$$
\begin{aligned} \color{#e93cac}b &= \color{#a68100}r(\frac{\color{#6e8e13}{s_y}}{\color{#1b8883}{s_x}}) \\ 
&= (\color{#a68100}{-0.868})(\frac{\color{#6e8e13}{1.619}}{\color{#1b8883}{3.399}}) \\ 
&= \color{#e93cac}{-0.413} \end{aligned}
$$
:::

---

*A researcher collected the following data on years of education ($X$) and number of children ($Y$) for a sample of married adults and produced the following raw data.*

::: {style="font-size: 0.9em; position: absolute; right: -75px; bottom: 0px; table-layout: fixed; width: 850px"}
|   | Education ($x_i$) | # Kids ($y_i$) | $x_i -\bar{x}$ | $\frac{x_i-\bar{x}}{s_x}$ | $y_i -\bar{y}$ | $\frac{y_i-\bar{y}}{s_y}$ | $(\frac{x_i-\bar{x}}{s_x})(\frac{y_i-\bar{y}}{s_y})$ |
|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
|   | 12 | 2 | -1.00 | -0.29  | -0.20 | -0.12 | 0.04 |
|   | 14 | 1  | 1.00 | 0.29  | -1.20  | -0.74 | -0.22  |
|   | 17 | 0  | 4.00 | 1.18 | -2.20 | -1.36 | -1.60 | 
|   | 10 | 3  | -3.00 | -0.88 | 0.80 | 0.49  | -0.44  |
|   | 8 | 5 | -5.00 | -1.47 | 2.80 | 1.73  | -2.54  |
|   | 9 | 3 | -4.00 | -1.18 | 0.80 | 0.49  | -0.58  |
|   | 12 | 4 | -1.00 | -0.29  | 1.80 | 1.11  | -0.33  |
|   | 14 | 2  | 1.00 | 0.29  | -0.20  | -0.12 | -0.04 |
|   | 18 | 0  | 5.00 | 1.47  | -2.20  | -1.36 | -2.00  |
|   | 16 | 2  | 3.00 | 0.88  | -0.20  | -0.12 | -0.11   |
| **sum** | 130 | 22 |   |  |  |  | -7.81 |  
| **mean** | [**13**]{style="color: #1b8883"} | [**2.2**]{style="color: #6e8e13"}  |   |  |  |  |  |  
| **st. dev.** | 3.399 | 1.619 |   |  |  | [**$r =$**]{style="color: #a68100"}  | [**$-0.868$**]{style="color: #a68100"} |

: {tbl-colwidths="[12, 17, 13, 11.5, 11.5, 11.5, 11.5, 12]"}
:::

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; top: 100px; left: -75px; text-align: center"}
2. Find the OLS regression line for the effect of education on number of kids
:::

::: {style="background: #e8e3d3; border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 300px; left: -25px; text-align: center; font-size: 1.25em; width: 200px;"}
$$
\widehat{y} = a + bx
$$
:::

::: {style="border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 457px; left: -75px; text-align: center; font-size: 1.25em"}
$$
\begin{aligned} \color{#754cbc}a &= \color{#6e8e13}{\bar{y}}- \color{#e93cac}{b}\color{#1b8883}{\bar{x}} \\ 
&= \color{#6e8e13}{2.20} - (\color{#e93cac}{-0.413})(\color{#1b8883}{13.00}) \\ 
&= \color{#754cbc}{7.569} \end{aligned}
$$


:::

---

*A researcher collected the following data on years of education ($X$) and number of children ($Y$) for a sample of married adults and produced the following raw data.*

::: {style="font-size: 0.9em; position: absolute; right: -75px; bottom: 0px; table-layout: fixed; width: 850px"}
|   | Education ($x_i$) | # Kids ($y_i$) | $x_i -\bar{x}$ | $\frac{x_i-\bar{x}}{s_x}$ | $y_i -\bar{y}$ | $\frac{y_i-\bar{y}}{s_y}$ | $(\frac{x_i-\bar{x}}{s_x})(\frac{y_i-\bar{y}}{s_y})$ |
|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
|   | 12 | 2 | -1.00 | -0.29  | -0.20 | -0.12 | 0.04 |
|   | 14 | 1  | 1.00 | 0.29  | -1.20  | -0.74 | -0.22  |
|   | 17 | 0  | 4.00 | 1.18 | -2.20 | -1.36 | -1.60 | 
|   | 10 | 3  | -3.00 | -0.88 | 0.80 | 0.49  | -0.44  |
|   | 8 | 5 | -5.00 | -1.47 | 2.80 | 1.73  | -2.54  |
|   | 9 | 3 | -4.00 | -1.18 | 0.80 | 0.49  | -0.58  |
|   | 12 | 4 | -1.00 | -0.29  | 1.80 | 1.11  | -0.33  |
|   | 14 | 2  | 1.00 | 0.29  | -0.20  | -0.12 | -0.04 |
|   | 18 | 0  | 5.00 | 1.47  | -2.20  | -1.36 | -2.00  |
|   | 16 | 2  | 3.00 | 0.88  | -0.20  | -0.12 | -0.11   |
| **sum** | 130 | 22 |   |  |  |  | -7.81 |  
| **mean** | 13 | 2.2 |   |  |  |  |  |  
| **st. dev.** | 3.399 | 1.619 |   |  |  | $r =$ | $-0.868$ |

: {tbl-colwidths="[12, 17, 13, 11.5, 11.5, 11.5, 11.5, 12]"}
:::

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; top: 100px; left: -75px; text-align: center"}
2. Find the OLS regression line for the effect of education on number of kids
:::

::: {style="background: #e8e3d3; border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 300px; left: -25px; text-align: center; font-size: 1.25em; width: 200px;"}
$$
\widehat{y} = a + bx
$$
:::

::: {style="border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 460px; left: -75px; text-align: center; font-size: 1.25em"}
$$
\widehat{y} = 7.569 - 0.413x
$$
:::

---

*A researcher collected the following data on years of education ($X$) and number of children ($Y$) for a sample of married adults and produced the following raw data.*

::: {style="font-size: 0.9em; position: absolute; right: -75px; bottom: 0px; table-layout: fixed; width: 850px"}
|   | Education ($x_i$) | # Kids ($y_i$) | $x_i -\bar{x}$ | $\frac{x_i-\bar{x}}{s_x}$ | $y_i -\bar{y}$ | $\frac{y_i-\bar{y}}{s_y}$ | $(\frac{x_i-\bar{x}}{s_x})(\frac{y_i-\bar{y}}{s_y})$ |
|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
|   | [**12**]{style="color: #1b8883"} | [**2**]{style="color: #754cbc"} | -1.00 | -0.29  | -0.20 | -0.12 | 0.04 |
|   | 14 | 1  | 1.00 | 0.29  | -1.20  | -0.74 | -0.22  |
|   | 17 | 0  | 4.00 | 1.18 | -2.20 | -1.36 | -1.60 | 
|   | 10 | 3  | -3.00 | -0.88 | 0.80 | 0.49  | -0.44  |
|   | 8 | 5 | -5.00 | -1.47 | 2.80 | 1.73  | -2.54  |
|   | 9 | 3 | -4.00 | -1.18 | 0.80 | 0.49  | -0.58  |
|   | 12 | 4 | -1.00 | -0.29  | 1.80 | 1.11  | -0.33  |
|   | 14 | 2  | 1.00 | 0.29  | -0.20  | -0.12 | -0.04 |
|   | 18 | 0  | 5.00 | 1.47  | -2.20  | -1.36 | -2.00  |
|   | 16 | 2  | 3.00 | 0.88  | -0.20  | -0.12 | -0.11   |
| **sum** | 130 | 22 |   |  |  |  | -7.81 |  
| **mean** | 13 | 2.2 |   |  |  |  |  |  
| **st. dev.** | 3.399 | 1.619 |   |  |  | $r =$ | $-0.868$ |

: {tbl-colwidths="[12, 17, 13, 11.5, 11.5, 11.5, 11.5, 12]"}
:::

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; top: 100px; left: -75px; text-align: center"}
3. What is the prediction error for the first person in the data set?
:::

::: {style="border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 220px; left: -50px; text-align: center; font-size: 1.25em"}
$$
\widehat{y} = 7.569 - 0.413x
$$
:::

::: {style="background: #e8e3d3; border: 4px solid black; border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 300px; left: -25px; text-align: center; font-size: 1.25em; width: 200px;"}
$$
\widehat{y} = a + bx
$$
:::

::: {.fragment style="border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 390px; left: -75px; text-align: center; font-size: 1.25em"}
$$
\text{prediction error} = y - \widehat{y}
$$
:::

::: {.fragment style="border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 460px; left: -75px; text-align: center; font-size: 1em"}
$$
\begin{aligned}
\color{#a68100}{\widehat{Kids_1}} &= 7.569 - 0.413(\color{#1b8883}{12}) \\
&= \color{#a68100}{2.613}
\end{aligned}
$$
:::

::: {.fragment style="border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; left: -75px; text-align: center; font-size: 1em"}
$$
\begin{aligned}
\text{prediction error} &= \color{#754cbc}{2} - \color{#a68100}{2.613} \\
&= -0.613
\end{aligned}
$$
:::

---

*A researcher collected the following data on years of education ($X$) and number of children ($Y$) for a sample of married adults and produced the following raw data.*

::: {style="font-size: 0.9em; position: absolute; right: -75px; bottom: 0px; table-layout: fixed; width: 850px"}
|   | Education ($x_i$) | # Kids ($y_i$) | $x_i -\bar{x}$ | $\frac{x_i-\bar{x}}{s_x}$ | $y_i -\bar{y}$ | $\frac{y_i-\bar{y}}{s_y}$ | $(\frac{x_i-\bar{x}}{s_x})(\frac{y_i-\bar{y}}{s_y})$ |
|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
|   | 12 | 2 | -1.00 | -0.29  | -0.20 | -0.12 | 0.04 |
|   | 14 | 1  | 1.00 | 0.29  | -1.20  | -0.74 | -0.22  |
|   | 17 | 0  | 4.00 | 1.18 | -2.20 | -1.36 | -1.60 | 
|   | 10 | 3  | -3.00 | -0.88 | 0.80 | 0.49  | -0.44  |
|   | 8 | 5 | -5.00 | -1.47 | 2.80 | 1.73  | -2.54  |
|   | 9 | 3 | -4.00 | -1.18 | 0.80 | 0.49  | -0.58  |
|   | 12 | 4 | -1.00 | -0.29  | 1.80 | 1.11  | -0.33  |
|   | 14 | 2  | 1.00 | 0.29  | -0.20  | -0.12 | -0.04 |
|   | 18 | 0  | 5.00 | 1.47  | -2.20  | -1.36 | -2.00  |
|   | 16 | 2  | 3.00 | 0.88  | -0.20  | -0.12 | -0.11   |
| **sum** | 130 | 22 |   |  |  |  | -7.81 |  
| **mean** | 13 | 2.2 |   |  |  |  |  |  
| **st. dev.** | 3.399 | 1.619 |   |  |  | [**$r =$**]{style="color: #e93cac"} | [**$-0.868$**]{style="color: #e93cac"} |

: {tbl-colwidths="[12, 17, 13, 11.5, 11.5, 11.5, 11.5, 12]"}
:::

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; top: 100px; left: -75px; text-align: center"}
4. Find and interpret the coefficient of determination
:::

::: {.fragment fragment-index=1 style="position: absolute; bottom: 150px; left: -75px; text-align: center; font-size: 1.25em;"}
$$
\begin{aligned}
\color{#a68100}{r} &= \color{#a68100}{-0.868} \\ R^2 &= (\color{#a68100}{r})(\color{#a68100}{r}) \\ 
&= (\color{#a68100}{-0.868})(\color{#a68100}{-0.868}) \\ 
&= 0.753 
\end{aligned}
$$
:::

::: {.fragment fragment-index=2 data-id="box5" style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; top: 170px; right: -50px; text-align: center; width: 450px"}
If we are predicting the number of kids individuals have, we will  reduce our errors of prediction by about $75\%$ if we take into consideration how much education these individuals have.
:::

::: {.fragment fragment-index=3 data-id="box3" style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; position: absolute; bottom: 170px; right: -50px; text-align: center; width: 450px"}
About $75\%$ of the variation in number of kids is explained by the diversity of education levels in the sample.
:::

---

### Statistical significance of regression componenets

:::: {.columns}

::: {.column width="45%"}

<br>
<br>
<br>

::: {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
[**STATISTICAL SIGNIFICANCE**]{.underline style="color: #44580c"} <br>
How certain can we be that the association exists in the population?
:::

<br>

::: {style="background: #e8e3d3; border: 4px solid black; border-radius: 15px; padding: 2px 2px 2px 2px; text-align: center; font-size: 2em;"}
$$
\widehat{y} = a + bx
$$
:::
:::
  
::: {.column width="55%"}
::: {.fragment style="border: 4px solid #1b8883; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
Rarely interested in statistical significance of the Y-intercept (whether the starting point of the line is different from $0$ in the population)
:::

<br>

::: {.fragment style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
There IS usually interest in whether the [slope]{.underline} is statistically significant (whether the change in the dependent variable associated with a one-unit change in the independent variable is different from $0$ in the population)
:::

<br>

::: {.fragment style="color: #e8e3d3; background: #1b8883; border: 4px solid #1b8883; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center"}
If $r$ is statistically significant then the bivariate slope is also statistically significant at the same alpha level.
:::
:::
  
::::

## {data-menu-title="Syllabus" background-iframe="https://vsass.github.io/SOC221/syllabus.html" background-interactive=TRUE}