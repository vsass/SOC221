---
title: '<h1 style="font-size:3em; "> Hypothesis testing for <br> one and two samples </h1>'
title-slide-attributes:
  data-background-image: ../images/abstract_statistics_playful2.jpeg
  data-background-size: cover
  data-background-opacity: "0.33"
subtitle: "SOC 221 • Lecture 7"
author: "Victoria Sass"
date: "July 15, 2024"
date-format: full
execute: 
  echo: true
  message: false
  warning: false
format: 
  revealjs:
    reference-location: margin
    theme: lecture_styles.scss
    controls: true
    slide-number: true
    chalkboard: true
    incremental: false 
    smaller: true
    preview-links: true
    history: false
    progress: true
    link-external-icon: true 
---

```{r}
#| echo: false
#| cache: false
require(tidyverse)
require(ggthemes)
require(gt)
require(gganimate)
require(ggforce)

knitr::opts_chunk$set(comment = ">")

# set transparent background in base
knitr::opts_chunk$set(dev.args=list(bg='transparent'))

# set transparent background in ggplot
ggplot2::theme_set(ggthemes::theme_tufte(base_size=12))
ggplot2::theme_update(panel.background = ggplot2::element_blank(),
                      plot.background=ggplot2::element_blank(),
    legend.background=ggplot2::element_blank())

options(width=80, show.signif.stars=FALSE)
```

# Hypothesis testing for one sample {.section-title background-color="#c5b4e3"}

--- 

### So far: 

#### Estimating an unknown population characteristic based on sample information

::: {style="position: absolute; top: 150px; right: 100px; font-size: 3em"}
[$\bar{X}$]{style="color:#1b8883"} ---INFERENCE--> [$\mu_x$]{style="color:#a68100"}
:::

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 550px; padding: 5px 5px 5px 5px; position: absolute; bottom: 175px; left: -50px; font-size: 1.25em"}
**Sample statistic**: The characteristic of the sample that we actually observe (i.e. the mean study time of a SAMPLE of UW students)
:::

::: {style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 550px; padding: 5px 5px 0px 5px; position: absolute; bottom: 50px; left: -50px;"}
*For example*: draw a random sample of 100 students and observe $\bar{X} = 14.5$
:::

::: {style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 550px; padding: 5px 5px 5px 5px; position: absolute; bottom: 175px; right: -50px; font-size: 1.25em"}
**Population parameter**: The characteristic of the population that we are interested in knowing (i.e. the mean study time of all UW students)
:::

::: {style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 550px; padding: 5px 5px 0px 5px; position: absolute; bottom: 50px; right: -50px;"}
[**Our goal**]{.underline}: Estimate the unknown population parameter $\mu_x = ?$
:::

---

### Another way to use our sample information

#### [NOW]{.underline}: Use our sample statistic to test an [hypothesis]{.underline style="color:#e93cac"} about the population

:::  {style="width: 600px; padding: 5px 5px 5px 5px; position: absolute; top: 100px; left: 175px; text-align: center; font-size: 1.5em"}
$$
\bar{X} = 14.5\text{ hours/week study time}
$$
:::

:::  {.fragment fragment-index=1 style="border: 4px solid black; width: 525px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; left: -75px; text-align: left; font-size: 1.25em"}
[Hypothesis:]{.underline .center}

* A claim about reality (i.e., about how the world works)<br>
* In our examples, the hypothesis is a statement about the reality of a parameter, like the population proportion, $\pi$, or the population mean, $\mu$.
:::

:::  {.fragment fragment-index=2 style="background: black; color: white; width: 630px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: -75px; text-align: left; font-size: 1.25em"}
[Hypothesis testing:]{.underline .center}

* We compare the [**known sample statistics**]{style="color:#e93cac"} to what the hypothesis implies.<br>
* Make a [**probability statement**]{style="color:#e93cac"} about how well the sample statistic corresponds with the hypothesis.<br>
* Probability statement = statement about [**statistical significance**]{style="color:#e93cac"}
:::

## Example: Test of Significance

Say we know that, on average, college students across the country study 13 hrs/week, with a standard deviation of 8.

[**Question: Do UW students really study more than the national average?**]{style="color: #a68100;"}

<br>

::: {.fragment fragment-index=1}
Insufficient time, energy, and money, so draw a random sample of UW students:
<br>
<br>
[N = 100, Mean = 14.5 hrs/week]{.center style="color: #e93cac;font-size: 1.25"}
:::

:::: {.columns}

::: {.column width="35%"}

<br>

::: {.fragment fragment-index=2}
Looks like UW students study more than the national average.
:::

<br>

::: {.fragment fragment-index=3}
But there are at least two explanations for this observation. . . 
:::


:::

::: {.column width="65%"}
:::  {.fragment fragment-index=4 style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 630px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: -75px; text-align: left;"}
[Explanation 1:]{.underline .center}

* UW students really do study more than 13 hours/week, on average<br>
* In other words, the observed differences between sample mean and the national average reflects a [real difference]{.underline} between the [population mean]{.underline} for all UW students and the national average
:::

:::  {.fragment fragment-index=4 style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 125px; padding: 5px 5px 5px 5px; position: absolute; bottom: 325px; right: -75px; text-align: left; font-size: 1.25"}
$\mu{UW} > 13$
:::
:::

::::

## Example: Test of Significance

Say we know that, on average, college students across the country study 13 hrs/week, with a standard deviation of 8.

[**Question: Do UW students really study more than the national average?**]{style="color: #a68100;"}

<br>


Insufficient time, energy, and money, so draw a random sample of UW students:
<br>
<br>
[N = 100, Mean = 14.5 hrs/week]{.center style="color: #e93cac;font-size: 1.25"}


:::: {.columns}

::: {.column width="35%"}

<br>


Looks like UW students study more than the national average.


<br>


But there are at least two explanations for this observation. . . 



:::

::: {.column width="65%"}
:::  {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 630px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: -75px; text-align: left;"}
[Explanation 2:]{.underline .center}

* We have drawn an unusual sample of UW students when, in reality, UW students don’t study more than the national average of 13 hours/week
* The difference we observe between the sample mean and the national average is just due to [chance sampling error]{.underline}
:::

:::  {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 125px; padding: 5px 5px 5px 5px; position: absolute; bottom: 325px; right: -75px; text-align: left; font-size: 1.25"}
$\mu{UW} = 13$
:::
:::

::::

---

:::: {.columns}

::: {.column width="30%"}

<br>

::: {style="color: #a68100; font-size: 1.25em"}
> Question: Do UW students really study more than the national average?
:::

<br>

::: {style="font-size: 1.25em"}
Have to decide between two explanations. . . 
[**TWO HYPOTHESES**]{style="color: #e93cac;"}
:::
:::

::: {.column width="70%"}

:::  {.fragment fragment-index=1 style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 125px; padding: 5px 5px 5px 5px; position: absolute; top: 135px; right: -75px; text-align: left; font-size: 1.25"}
$\mu{UW} > 13$
:::

:::  {.fragment fragment-index=1 style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 630px; padding: 5px 5px 5px 5px; position: absolute; top: 25px; right: 75px; text-align: left;"}
[Explanation 1:]{.underline .center}

* UW students really do study more than 13 hours/week, on average<br>
* In other words, the observed differences between sample mean and the national average reflects a [real difference]{.underline} between the [population mean]{.underline} for all UW students and the national average
:::

:::  {.fragment fragment-index=2 style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 125px; padding: 5px 5px 5px 5px; position: absolute; bottom: 135px; right: -75px; text-align: left; font-size: 1.25"}
$\mu{UW} = 13$
:::

:::  {.fragment fragment-index=2 style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 630px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: 75px; text-align: left;"}
[Explanation 2:]{.underline .center}

* We have drawn an unusual sample of UW students when, in reality, UW students don’t study more than the national average of 13 hours/week
* The difference we observe between the sample mean and the national average is just due to [chance sampling error]{.underline}
:::

:::

::::

---

:::: {.columns}

::: {.column width="30%"}

<br>

::: {.fragment fragment-index=2 style="font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
States that there **IS** a real difference in the population (difference not just due to chance)
:::

<br>

::: {style="font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
States that there is **NO** real difference in the population (sample result happened by chance)
:::
:::

::: {.column width="70%"}

:::  {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 125px; padding: 5px 5px 5px 5px; position: absolute; top: 135px; right: -75px; text-align: left; font-size: 1.25"}
$\mu{UW} > 13$
:::

:::  {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 630px; padding: 5px 5px 5px 5px; position: absolute; top: 25px; right: 75px; text-align: left;"}
[Explanation 1:]{.underline .center}

* UW students really do study more than 13 hours/week, on average<br>
* In other words, the observed differences between sample mean and the national average reflects a [real difference]{.underline} between the [population mean]{.underline} for all UW students and the national average
:::

:::  {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 125px; padding: 5px 5px 5px 5px; position: absolute; bottom: 135px; right: -75px; text-align: left; font-size: 1.25"}
$\mu{UW} = 13$
:::

:::  {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 630px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: 75px; text-align: left;"}
[Explanation 2:]{.underline .center}

* We have drawn an unusual sample of UW students when, in reality, UW students don’t study more than the national average of 13 hours/week
* The difference we observe between the sample mean and the national average is just due to [chance sampling error]{.underline}
:::

:::

::::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

::: fragment
#### Key question:
[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}
:::

* Set up a **test** assuming that the null $H_0$ is true and see whether the facts of our sample contradict that assumption.
    *  In other words, if the null hypothesis were true, [how likely]{.underline} is it that the sample result just occurred by chance?

::: {.fragment style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 650px; padding: 5px 5px 5px 5px; position: absolute; bottom: 75px; right: 0px; text-align: center;"}
If the probability of observing the sample result is low (i.e., sample results are really inconsistent with the null hypothesis) then we [**REJECT**]{.underline} the null hypothesis.

<br>

This would [**SUPPORT**]{.underline} the alternative hypothesis.
:::

:::

::::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}


#### Key question:
[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}

* Set up a **test** assuming that the null $H_0$ is true and see whether the facts of our sample contradict that assumption.
    *  In other words, if the null hypothesis were true, [how likely]{.underline} is it that the sample result just occurred by chance?

::: {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 650px; padding: 5px 5px 5px 5px; position: absolute; bottom: 40px; right: 0px; text-align: center;"}
If, on the other hand, the probability of observing the sample result is too high (i.e., sample results are somewhat consistent with the null hypothesis) then we **FAIL TO REJECT** the null hypothesis.


<br>

This would **FAIL TO SUPPORT** the alternative hypothesis.
:::

:::

::::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}


#### Key question:
[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}

* Set up a **test** assuming that the null $H_0$ is true and see whether the facts of our sample contradict that assumption.
    *  In other words, if the null hypothesis were true, [how likely]{.underline} is it that the sample result just occurred by chance?
    
<br>    
  
* Our [**key question**]{style="color: #e93cac;"} requires us to make a [PROBABILITY STATEMENT]{.underline} about the sample.
    * So, think about the probability distribution from which the sample comes.
    * Probability distribution of all possible sample results is the [SAMPLING DISTRIBUTION]{.underline}.



:::

::::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

#### If the [**null hypothesis were true**]{.underline style="color: #754cbc"}, what would the sampling distribution look like?


* Central Limit theorem tells us: 
    * Sampling distribution is **NORMAL**
    * $\mu_{\bar{X}} = \mu_X$
    * $\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}$

:::

::::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

#### If the [**null hypothesis were true**]{.underline style="color: #754cbc"}, what would the sampling distribution look like?

* Central Limit theorem tells us: 
    * Sampling distribution is **NORMAL**
    * $\mu_{\bar{X}} = \mu_X$
    * $\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}$

::: {style="position: absolute; bottom: 50px; right: -50px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center
hrs <- data.frame(x = c(-3.5, 3.5))
ggplot(data = hrs, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1), linewidth = 1) + 
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 

```
:::

:::

::::

::: {.fragment fragment-index=1 data-id="box5" style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: 175px; text-align: center; font-size: 1.25em"}
$\mu_{\bar{X}_{UW}} = \mu_{UW} = 13$
:::

::: {.fragment fragment-index=1 data-id="box5" style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 250px; padding: 5px 5px 5px 5px; position: absolute; bottom: 325px; right: 450px; text-align: center; font-size: 1.25em"}
$\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{8.0}{\sqrt{100}}$
:::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

#### [Key question]{.underline}

[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}

::: {.fragment fragment-index=1}
Think about where our ONE SINGLE sample falls in this distribution.
:::

::: {.fragment fragment-index=2 data-id="box5" style="border: 4px solid #e93cac; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 150px; right: -75px; text-align: center;"}
14.5 is out on this side of the distribution, but how far?
:::

::: {.fragment fragment-index=3 data-id="box5" style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; bottom: 350px; right: 415px; text-align: center;"}
We need to convert our score to a z-score
:::

::: {data-id="box5" style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; position: absolute; bottom: 150px; right: 540px; text-align: center; font-size: 1.25em"}
$\sigma_{\bar{X}} = 0.8$
:::

::: {.fragment fragment-index=3 data-id="box5" style="width: 400px; padding: 5px 5px 5px 5px; position: absolute; top: 185px; right: -100px; text-align: center; font-size: 1.25em"}
$z = \frac{\bar{X} -  \mu_{0}}{\sigma_{\bar{X}}}$
<br>
<br>
$= \frac{14.5 - 13}{0.8} = 1.875$
:::

::: {style="position: absolute; bottom: 50px; right: -50px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center
hrs <- data.frame(x = c(-3.5, 3.5))
ggplot(data = hrs, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1), linewidth = 1) + 
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 

```
:::

:::

::::

::: {data-id="box5" style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: 175px; text-align: center; font-size: 1.25em"}
$\mu_{\bar{X}_{UW}} = \mu_{UW} = 13$
:::

::: {.fragment fragment-index=4 data-id="box5" style="background: #e93cac; border: 4px solid #690c48; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 150px; right: -75px; text-align: center; font-size: 0.85em"}
14.5 is [1.875]{.underline} standard errors away from what we assume under the null hypothesis
:::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

#### [Key question]{.underline}

[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}

What is the probability of randomly selecting a case that is [1.875]{style="color: #e93cac;"} standard deviations above the mean of a normal distribution?

<br>

::: fragment
We need to find the<br>probability associated<br>with a [**z-score of 1.875**]{style="color: #e93cac;"}<br>in the [standard<br>normal table](https://www.calculator.net/z-score-calculator.html)
:::


::: {style="position: absolute; bottom: 50px; right: -50px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center
hrs <- data.frame(x = c(-3.5, 3.5))
ggplot(data = hrs, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1), linewidth = 1) + 
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 

```
:::

:::

::::

::: {data-id="box5" style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: 175px; text-align: center; font-size: 1.25em"}
$\mu_{\bar{X}_{UW}} = \mu_{UW} = 13$
:::

::: {data-id="box5" style="background: #e93cac; border: 4px solid #690c48; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 150px; right: -75px; text-align: center; font-size: 0.85em"}
14.5 is [1.875]{.underline} standard errors away from what we assume under the null hypothesis
:::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

#### [Key question]{.underline}

[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}

What is the probability of randomly selecting a case that is [1.875]{style="color: #e93cac;"} standard deviations above the mean of a normal distribution?

<br>

::: fragment
The proportion of cases<br>below z of 1.875<br>is [**0.9696**]{style="background: darkgrey;"}
:::


::: {style="position: absolute; bottom: 50px; right: -50px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

# function to shade lower part of distribution
funcShaded_lower <- function(x, upper_bound) {
    y = dnorm(x, mean = mu, sd = sigma)
    y[x > upper_bound] <- NA
    return(y)
}

# function to shade middle part of distribution
funcShaded_middle <- function(x, upper_bound, lower_bound) {
    y = dnorm(x, mean = mu, sd = sigma)
    y[x > upper_bound] <- NA
    y[x < lower_bound] <- NA
    return(y)
}

# function to shade upper part of distribution
funcShaded_upper <- function(x, lower_bound) {
    y = dnorm(x, mean = mu, sd = sigma)
    y[x < lower_bound] <- NA
    return(y)
}

mu <- 0
sigma <- 1
z <- 1.875

hrs <- data.frame(x = c(-3.5, 3.5))
ggplot(data = hrs, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_lower, args = list(upper_bound = z), 
                  geom = "area", fill = "darkgrey", alpha = .5) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 


```
:::

:::

::::

::: {data-id="box5" style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: 175px; text-align: center; font-size: 1.25em"}
$\mu_{\bar{X}_{UW}} = \mu_{UW} = 13$
:::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

#### [Key question]{.underline}

[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}

What is the probability of randomly selecting a case that is [1.875]{style="color: #e93cac;"} standard deviations above the mean of a normal distribution?

<br>

The proportion of cases<br>below z of 1.875<br>is [**0.9696**]{style="background: darkgrey;"}



::: {style="position: absolute; bottom: 50px; right: -50px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

mu <- 0
sigma <- 1
z <- 1.875

hrs <- data.frame(x = c(-3.5, 3.5))
ggplot(data = hrs, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_upper, args = list(lower_bound = z - 0.1), 
                  geom = "area", fill = "#e93cac", alpha = .5) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 


```
:::

:::

::::

::: {data-id="box5" style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: 175px; text-align: center; font-size: 1.25em"}
$\mu_{\bar{X}_{UW}} = \mu_{UW} = 13$
:::

::: {style="background: #e93cac; border: 4px solid #690c48; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 150px; right: -75px; text-align: center; font-size: 0.85em"}
Probability of observing a case from this part is $1 -.9696 =.0304$

:::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

#### [Key question]{.underline}

[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}

**So, the probability of randomly selecting a sample with a mean as large as 14.5 from a population with a mean of 13 is only 0.0304**

<br>

The proportion of cases<br>below z of 1.875<br>is [**0.9696**]{style="background: darkgrey;"}



::: {style="position: absolute; bottom: 50px; right: -50px"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

mu <- 0
sigma <- 1
z <- 1.875

hrs <- data.frame(x = c(-3.5, 3.5))
ggplot(data = hrs, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_upper, args = list(lower_bound = z - 0.1), 
                  geom = "area", fill = "#e93cac", alpha = .5) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 


```
:::

:::

::::

::: {data-id="box5" style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 300px; padding: 5px 5px 5px 5px; position: absolute; bottom: 0px; right: 175px; text-align: center; font-size: 1.25em"}
$\mu_{\bar{X}_{UW}} = \mu_{UW} = 13$
:::

::: {style="background: #e93cac; border: 4px solid #690c48; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 150px; right: -75px; text-align: center; font-size: 0.85em"}
Probability of observing a case from this part is $1 -.9696 =.0304$

:::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

#### [Key question]{.underline}

[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}

**So, the probability of randomly selecting a sample with a mean as large as 14.5 from a population with a mean of 13 is only [0.0304]{style="color: #a68100;"}**

<br>

:::

::::

::: {.fragment style="font-size: 1.5em; position: absolute; top: 275px; left: 350px"}
> [**P-VALUE**]{style="color: #a68100;"}: The probability of observing the sample result if the null hypothesis were actually true.
:::

::: {.fragment style="font-size: 1.25em; position: absolute; bottom: 50px; left: 450px"}
i.e., the probability that the null hypothesis is [**true**]{.underline}, given our sample results
:::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

#### [Key question]{.underline}

[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}

**So, the probability of randomly selecting a sample with a mean as large as 14.5 from a population with a mean of 13 is only [0.0304]{style="color: #a68100;"}**

<br>

:::

::::

::: {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 650px; padding: 5px 5px 5px 5px; position: absolute; bottom: 200px; right: 0px; text-align: center;"}
Since the [**P-VALUE**]{style="background: #a68100;"} is small (the sample result is unlikely to have occurred if the null hypothesis were actually true we
<br> 
[**REJECT THE NULL HYPOTHESIS**]{style="font-size: 1.25em"}
:::

::: {.fragment style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 550px; padding: 5px 5px 5px 5px; position: absolute; bottom: 40px; right: 40px; text-align: center;"}
[**SUPPORT THE ALTERNATIVE HYPOTHESIS**]{style="font-size: 1.25em"}
:::

---

:::: {.columns}

::: {.column width="30%"}

::: {style="border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #6e8e13"}
**ALTERNATIVE HYPOTHESIS ($H_a$)**<br>
$$\mu{UW} > 13$$
[(*sample result reflects a real difference*)]{.smaller}
:::

<br>

::: {style="border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.20em; color: #754cbc"}
**NULL**<br>**HYPOTHESIS: ($H_0$)**<br>
$$\mu{UW} = 13$$
[(*sample result just happened by chance*)]{.smaller}
:::
:::

::: {.column width="70%"}

#### [Key question]{.underline}

[How likely is it that we would observe a sample mean of 14.5 if, in reality, the population of UW students really don’t study more than 13 hours per week?]{style="color: #e93cac;"}

<br>

* When we reject the null hypothesis we say that the sample result is [**statistically significant**]{.underline style="color: #e93cac;"}
    * statistically unlikely to have occurred just by chance
    * Likely represents a real difference in the population

<br>

:::

::::



::: {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 550px; padding: 5px 5px 5px 5px; position: absolute; bottom: 40px; right: 40px; text-align: center;"}
[**SUPPORT THE ALTERNATIVE HYPOTHESIS**]{style="font-size: 1.25em"}
:::

---

:::: {.columns}

::: {.column width="40%"}
<br>

::: {style="font-size: 2em;"}
> [**P-VALUE**]{style="color: #e93cac;"}: The probability of observing the sample result if the null hypothesis were actually true.
:::
:::

::: {.column width="60%"}
::: {style="font-size: 1.5em; position: static; text-align: center"}
When the [**P-VALUE**]{style="color: #e93cac;"} is [*small*]{.underline} we:<br>
[**REJECT THE NULL HYPOTHESIS**]{style="color: #754cbc;"}, <br>
[**SUPPORT THE ALTERNATIVE HYPOTHESIS**]{style="color: #6e8e13;"} <br>
and say that the result is <br>
[**STATISTICALLY SIGNIFICANT**]{style="color: #e93cac;"}
:::

<br>

::: {.fragment style="font-size: 1.25em; position: static; text-align: center"}
Question: How small does the [P-value]{style="color: #e93cac;"} have to be before we reject the null hypothesis?
:::

<br>

::: {.fragment style="font-size: 1.25em; position: static; text-align: center"}
Answer: We decide on that standard before our test by setting the [**ALPHA LEVEL ($\alpha$)**]{style="color: #e93cac;"} for the test
:::
:::

::::

---

:::: {.columns}

::: {.column width="40%"}

::: {style="font-size: 1.9em;"}
> [**ALPHA $(\alpha)$**]{style="color: #e93cac;"}: The probability [*threshold*]{.underline} at which we are willing to reject the null hypothesis.
:::
:::

::: {.column width="60%"}
::: {style="font-size: 1.4em; position: static; text-align: center"}
[**$\text{p-value} \lt \alpha$**]{style="color: #e93cac;"}<br>
we [**REJECT THE NULL HYPOTHESIS**]{style="color: #754cbc;"}, <br>
[**SUPPORT THE ALTERNATIVE HYPOTHESIS**]{style="color: #6e8e13;"} <br>
and say that the result is <br>
[**STATISTICALLY SIGNIFICANT**]{style="color: #e93cac;"}
:::

::: {.fragment style="font-size: 1.25em; position: static; text-align: center;"}
Standard choices for $\alpha$:<br>
0.05<br>
0.01<br>
0.001
:::


:::

::::

---

:::: {.columns}

::: {.column width="40%"}

::: {style="font-size: 1.9em;"}
> [**ALPHA $(\alpha)$**]{style="color: #e93cac;"}: The probability [*threshold*]{.underline} at which we are willing to reject the null hypothesis.
:::
:::

::: {.column width="60%"}
::: {style="font-size: 1.4em; position: static; text-align: center"}
[**$\text{p-value} \lt \alpha$**]{style="color: #e93cac;"}<br>
we [**REJECT THE NULL HYPOTHESIS**]{style="color: #754cbc;"}, <br>
[**SUPPORT THE ALTERNATIVE HYPOTHESIS**]{style="color: #6e8e13;"} <br>
and say that the result is <br>
[**STATISTICALLY SIGNIFICANT**]{style="color: #e93cac;"}
:::

::: {style="font-size: 1.25em; position: static; text-align: center;"}
Standard choices for $\alpha$:<br>
[**0.05**]{style="color: #1b8883;"}<br>
0.01<br>
0.001
:::

:::

::::

::: {style="font-size: 0.85em; position: absolute; right: -75px; top: 350px; text-align: center; padding: 5px 5px 5px 5px; background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 300px;"}
Not willing to reject the null hypothesis unless there is less than a [**5% chance**]{.underline} that the sample result (difference) appeared  just because of random sampling error.
:::

::: {.fragment fragment-index=1 style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 750px; padding: 0px 0px 0px 0px; position: absolute; bottom: 100px; left: 25px; text-align: center"}
Even with these high standards, we never call this proof because another sample may lead to a different decision.
:::

::: {.fragment fragment-index=2 style="background: #e93cac; border: 4px solid #690c48; border-radius: 15px; width: 750px; padding: padding: 0px 0px 0px 0px; position: absolute; bottom: 0px; left: 25px; text-align: center"}
So we [**NEVER ACCEPT AN HYPOTHESIS**]{.underline}!<br>
(can only reject or retain / support or fail to support)

:::

---

### Important notes on results of hypothesis tests

<br>

::: incremental
* Never *accept* or *prove* an hypothesis
    * Your decision reflects just the evidence available in the current sample
    * A new sample may produce a different result and the *accepted* or *proven* hypothesis may be wrong
* Statistically significant results can happen by chance
    * $\text{p-value} = 0.05$ means that there is a $5\%$ chance of claiming statistical significance for a non-existent difference
* Statistically significant $\ne$ substantively significant
    * Tiny real-world differences can be statistically significant, especially with high power (big samples)
    * Important differences can look statistically non-significant, especially with low power (small samples)
:::

## Another example

<br>

*The university tells us that the average student on campus consumes 2 drinks per week with a standard deviation of 1.9.  They have asked us to determine whether students living in the Greek system are different from the university average in terms of average number of drinks per week.*

<br>

::: {.fragment style="text-align: center; font-size: 1.25em"}
Draw a random sample of students from Greek system: <br>
[$n = 150$, Mean = $2.3$ drinks/week]{style="color: #e93cac;"}
:::

## Steps for Hypothesis / Significance Tests

<br>

::: incremental
* **Step 1: Plan**
    * State the null and alternative [hypotheses]{style="color: #e93cac;"}
    * Choose your [alpha]{style="color: #e93cac;"} level and find the [critical value]{style="color: #e93cac;"}
* **Step 2: Calculate**
    * Calculate [test statistic]{style="color: #e93cac;"} (and [p-value]{style="color: #e93cac;"})
* **Step 3: Make a decision**
    * [Reject $H_0$ and support $H_a$ if]{style="color: #6e8e13;"}
        * p-value < alpha
        * Test statistic more extreme than critical value
    * [Fail to reject $H_0$ and fail to support $H_a$ if]{style="color: #754cbc;"}
        * p-value > alpha
        * Test statistic less extreme than critical value
:::

## Step 1: Plan

#### State the null and alternative [hypotheses]{style="color: #e93cac;"}

*The university tells us that the average student on campus consumes 2 drinks per week with a standard deviation of 1.9.  They have asked us to determine whether students living in the Greek system are different from the university average in terms of average number of drinks per week.*

::: {style="text-align: center; font-size: 1.25em"}
Draw a random sample of students from Greek system: <br>
[$n = 150$, Mean = $2.3$ drinks/week]{style="color: #e93cac;"}
:::

:::: {.columns}

::: {.column width="40%"}

<br>

::: {.fragment fragment-index=1 style="color: #754cbc; text-align: center; font-size: 1.25em"}
**NULL HYPOTHESIS:**
:::

<br>

::: {.fragment fragment-index=2 style="color: #6e8e13; text-align: center; font-size: 1.25em"}
**ALTERNATIVE**
<br>
**HYPOTHESIS:**
:::

:::

::: {.column width="30%"}
::: {.fragment fragment-index=1 style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
$$
\mu_{greek} = 2
$$
:::

::: {.fragment fragment-index=2 style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
$$
\mu_{greek} \ne 2
$$
:::

:::

::: {.column width="30%"}
::: {.fragment fragment-index=3 style="border: 4px solid black; border-radius: 15px; width: 350px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
Set up a test assuming that the [null $H_0$]{style="color: #754cbc;"} is true and see whether the facts of our sample contradict that assumption.
:::
:::

::::

::: {.fragment fragment-index=4 style="background: black; color: white; width: 375px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em; position: absolute; bottom: 177px; right: -70px;"}
Stated in terms of unknown population parameters
:::

::: {.fragment fragment-index=4 style="background: black; color: white; 15px; width: 375px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em; position: absolute; bottom: 25px; right: -70px;"}
This is a [**TWO-SIDED**]{style="color: #ffc700;"} (non-directional) hypothesis
:::

## One-sided versus two-sided

:::: {.columns}

::: {.column width="50%"}

::: {.fragment fragment-index=4 style="text-align: center; font-size: 1.25em; "}
A [**ONE-SIDED**]{style="color: #1b8883;"} test is one in which we are interested if the unknown population parameter is **HIGHER** *or* **LOWER** than the value assumed under the null hypothesis
:::

::: {.fragment fragment-index=5 style="border: 3px solid #1b8883; text-align: center; font-size: 1.25em; "}
Example: Do women have a [higher]{.underline} level of emotional intelligence than do men?

:::

<br>

::: {.fragment fragment-index=6 style="border: 3px solid #1b8883; text-align: center; font-size: 1.25em; "}
Reject null hypothesis if the test result is [different]{.underline} enough from the null [in the right direction]{.underline}
:::

:::

::: {.column width="50%"}
::: {.fragment fragment-index=1 style="text-align: center; font-size: 1.25em; "}
A [**TWO-SIDED**]{style="color: #a68100;"} test is one in which we are interested if the unknown population parameter is just **DIFFERENT** from the value assumed under the null hypothesis
:::


::: {.fragment fragment-index=2 style="border: 4px solid #a68100; text-align: center; font-size: 1.25em; "}
Example: Are men and women [different]{.underline} in terms of emotional intelligence?
:::

<br>

::: {.fragment fragment-index=3 style="border: 4px solid #a68100; text-align: center; font-size: 1.25em; "}
Reject null hypothesis if the test result is [EITHER]{.underline} much higher [OR]{.underline} much lower than what we assume under the null
:::

:::

::::

## One-sided versus two-sided

:::: {.columns}

::: {.column width="50%"}

::: {style="text-align: center; font-size: 1.25em; "}
A [**ONE-SIDED**]{style="color: #1b8883;"} test is one in which we are interested if the unknown population parameter is **HIGHER** *or* **LOWER** than the value assumed under the null hypothesis
:::

```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

mu <- 0
sigma <- 1
z <- -1.645

eq <- data.frame(x = c(-3.5, 3.5))
ggplot(data = eq, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_lower, args = list(upper_bound = z), 
                  geom = "area", fill = "#1b8883", alpha = .75) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 
```

::: {.fragment fragment-index=1 style="border: 4px solid #1b8883; text-align: center; font-size: 1em;"}
Only one side contains strong results consistent with our research hypothesis
:::

:::

::: {.column width="50%"}
::: {style="text-align: center; font-size: 1.25em; "}
A [**TWO-SIDED**]{style="color: #a68100;"} test is one in which we are interested if the unknown population parameter is just **DIFFERENT** from the value assumed under the null hypothesis
:::

```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

z2 <- 2.241
z1 <- -2.241

ggplot(data = eq, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_lower, args = list(upper_bound = z1), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  stat_function(fun = funcShaded_upper, args = list(lower_bound = z2), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 
```


::: {.fragment fragment-index=2 style="border: 4px solid #a68100; text-align: center; font-size: 1em;"}
Both of these areas contain strong results consistent with our research hypothesis
:::

:::

::::

## One-sided or two-sided? {visibility="hidden"}

<br>

::: incremental
* Are Friday classes, on average, shorter than the standard 50 minutes?
    * [One-sided]{style="color: #1b8883;"}
* Are bars with pool tables different from bars without pool tables different in terms of average cover charge?
    * [Two-sided]{style="color: #a68100;"}
* Is the average education of immigrants lower than the national average?
    * [One-sided]{style="color: #1b8883;"}
* Do professors drink more coffee than do students?
    * [One-sided]{style="color: #1b8883;"}
:::

## One-sided versus two-sided

:::: {.columns}

::: {.column width="50%"}

::: {style="text-align: center; font-size: 1.25em; "}
A [**ONE-SIDED**]{style="color: #1b8883;"} test is one in which we are interested if the unknown population parameter is **HIGHER** *or* **LOWER** than the value assumed under the null hypothesis
:::

```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

mu <- 0
sigma <- 1
z <- -1.645

eq <- data.frame(x = c(-3.5, 3.5))
ggplot(data = eq, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_lower, args = list(upper_bound = z), 
                  geom = "area", fill = "#1b8883", alpha = .75) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 
```

:::

::: {.column width="50%"}
::: {style="text-align: center; font-size: 1.25em; "}
A [**TWO-SIDED**]{style="color: #a68100;"} test is one in which we are interested if the unknown population parameter is just **DIFFERENT** from the value assumed under the null hypothesis
:::

```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

z2 <- 2.241
z1 <- -2.241

ggplot(data = eq, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_lower, args = list(upper_bound = z1), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  stat_function(fun = funcShaded_upper, args = list(lower_bound = z2), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 
```

:::

::::

::: {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1em;"}
Same null hypothesis (that there is no difference) contradicts both one- and two-sided alternative hypotheses.
:::

---

### Structure of hypothesis determines the [critical value]{style="color: #e93cac;"}

::: {style="font-size: 1.5em;"}
> [**Critical value**]{style="color: #e93cac;"}: The minimum value at which the test statistic would lead you to reject the null hypothesis
:::

* Values that are more extreme than the critical value are so unlikely under the null hypothesis (have such low p-values) that they lead you to believe that the null hypothesis is not true.
* Critical value determined by the [alpha level]{.underline} and the [structure of the hypothesis]{.underline} (one- or two-sided)

:::: {.columns}

::: {.column width="50%"}
::: {.fragment fragment-index=1}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

mu <- 0
sigma <- 1
z <- -1.645

eq <- data.frame(x = c(-3.5, 3.5))
ggplot(data = eq, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_lower, args = list(upper_bound = z), 
                  geom = "area", fill = "#1b8883", alpha = .75) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 
```
:::
:::

::: {.column width="50%"}
::: {.fragment fragment-index=1}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

z2 <- 2.241
z1 <- -2.241

ggplot(data = eq, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_lower, args = list(upper_bound = z1), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  stat_function(fun = funcShaded_upper, args = list(lower_bound = z2), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 
```
:::
:::

::::

::: {.fragment fragment-index=1 style="background: black; color: white; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 100px; right: 425px; text-align: center"}
Normal<br>
distribution<br>
$\alpha = 0.05$
:::

::: {.fragment fragment-index=2 style="background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 100px; left: -75px; text-align: center"}
$H_a: \mu \lt 0$<br>
Critical value of<br>
$z = -1.65$
:::

::: {.fragment fragment-index=2 style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 100px; right: -75px; text-align: center"}
$H_a: \mu \ne 0$<br>
Critical value of<br>
$z = \pm 1.96$
:::

## Step 1: Plan

#### Choose your [alpha]{style="color: #e93cac;"} level and find the [critical value]{style="color: #e93cac;"}

*The university tells us that the average student on campus consumes 2 drinks per week with a standard deviation of 1.9.  They have asked us to determine whether students living in the Greek system are different from the university average in terms of average number of drinks per week.*

::: {style="text-align: center; font-size: 1.25em"}
Draw a random sample of students from Greek system: <br>
[$n = 150$, Mean = $2.3$ drinks/week]{style="color: #e93cac;"}
:::

:::: {.columns}

::: {.column width="30%"}
::: {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 250px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
$$
H_0: \mu_{greek} = 2
$$
:::

::: {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 250px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
$$
H_a: \mu_{greek} \ne 2
$$
:::

:::

::: {.column width="70%"}
::: {.fragment fragment-index=2}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

z2 <- 2.241
z1 <- -2.241

ggplot(data = eq, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_lower, args = list(upper_bound = z1), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  stat_function(fun = funcShaded_upper, args = list(lower_bound = z2), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 
```
:::
:::

::::

::: {.fragment .fade-in-then-out fragment-index=1 style="background: black; color: white; 15px; width: 375px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em; position: absolute; bottom: 125px; left: 400px;"}
This is a [**TWO-SIDED**]{style="color: #ffc700;"} (non-directional) hypothesis
:::

::: {.fragment fragment-index=2 style="background: black; color: white; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 125px; left: 325px; text-align: center"}
Normal<br>
distribution<br>
[$\alpha = 0.05$]{style="color: #e93cac;"}
:::

::: {.fragment fragment-index=2 style="width: 300px; position: absolute; bottom: 225px; right: -75px; text-align: center; font-size: 0.85em;border: 3px solid black;"}
So our sample result has to be at least [1.96]{style="color: #e93cac;"} standard errors away from what is assumed under $H_0$ for us to reject $H_0$
:::

::: {.fragment fragment-index=2 style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 50px; right: -75px; text-align: center"}
$H_a: \mu \ne 0$<br>
Critical value of<br>
[$z = \pm 1.96$]{style="color: #e93cac;"}
:::

## Step 2: Calculate

#### Calculate [test statistic]{style="color: #e93cac;"} (and [p-value]{style="color: #e93cac;"})

*The university tells us that the average student on campus consumes 2 drinks per week with a standard deviation of 1.9.  They have asked us to determine whether students living in the Greek system are different from the university average in terms of average number of drinks per week.*

::: {style="text-align: center; font-size: 1.25em"}
Draw a random sample of students from Greek system: <br>
[$n = 150$, Mean = $2.3$ drinks/week]{style="color: #e93cac;"}
:::

:::: {.columns}

::: {.column width="30%"}
::: {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 250px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
$$
H_0: \mu_{greek} = 2
$$
:::

::: {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 250px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
$$
H_a: \mu_{greek} \ne 2
$$
:::

:::

::: {.column width="40%"}
::: {.fragment fragment-index=1}
Figuring out how far the sample result is fom $H_0$ and putting it in standard-error units
:::

::: {.fragment fragment-index=1 style="font-size: 1.25em"}
$$
\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{1.9}{\sqrt{150}} = 0.155
$$
:::
:::

::: {.column width="30%"}
::: {.fragment fragment-index=2 style="font-size: 2em; text-align: end"}
[$z$]{style="color: #e93cac;"} $= \frac{\bar{X} - \mu_0}{\sigma_{\bar{X}}}$

$\frac{2.3-2}{0.155} =$ [$1.94$]{style="color: #e93cac;"}
:::
:::

::::

::: {.fragment fragment-index=3 style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 800px; padding: 0px 0px 0px 0px; position: absolute; bottom: 0px; right: -50px; text-align: center; font-size: 0.85em"}
So, the average number of drinks for the Greeks is [$1.94$]{style="color: #e93cac;"} standard errors above what we assume under $H_0$ 
:::

## Step 3: Make a decision

#### [Fail to reject $H_0$ and fail to support $H_a$]{style="color: #e93cac;"}

*The university tells us that the average student on campus consumes 2 drinks per week with a standard deviation of 1.9.  They have asked us to determine whether students living in the Greek system are different from the university average in terms of average number of drinks per week.*

::: {style="text-align: center; font-size: 1.25em"}
Draw a random sample of students from Greek system: <br>
[$n = 150$, Mean = $2.3$ drinks/week]{style="color: #e93cac;"}
:::

:::: {.columns}

::: {.column width="30%"}
::: {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 250px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
$$
H_0: \mu_{greek} = 2
$$
:::

::: {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 250px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.5em"}
$$
H_a: \mu_{greek} \ne 2
$$
:::

:::

::: {.column width="70%"}
::: {style="border: 4px solid #754cbc; border-radius: 15px; text-align: center"}
Since our [test statistic]{style="color: #e93cac;"} ([$1.94$]{style="color: #e93cac;"}) is less extreme than the [critical value]{style="color: #e93cac;"} ([$1.96$]{style="color: #e93cac;"}) we<br>
[FAIL TO REJECT $H_0$]{style="color: #754cbc; font-size: 1.25em"}
:::

::: {.fragment fragment-index=1}
* [Not enough evidence]{.underline} to say that Greeks drink more than other students
* [Observed difference]{.underling} is **NOT statistically significant** (may have just occurred by chance)
:::
:::

::::

## Practice

:::: {.columns}

::: {.column width="40%"}
*You are interested in knowing whether immigrants (US residents born outside of the country) are different from the US population as a whole in terms of educational attainment.  You draw a random sample of 225 adult immigrants and find that their average level of education is 13.3 years.  Compare this to the statistics for the population of American adults which has an average education of 12.75 with a standard deviation of 4 years.  Use a .05 alpha level to test the statistical significance of the observed difference.*
:::

::: {.column width="60%"}
::: {.fragment style="border: 3px solid black;"}
* **Step 1: Plan**
    * State the null and alternative [hypotheses]{style="color: #e93cac;"}
    * Choose your [alpha]{style="color: #e93cac;"} level and find the [critical value]{style="color: #e93cac;"}
* **Step 2: Calculate**
    * Calculate [test statistic]{style="color: #e93cac;"} (and [p-value]{style="color: #e93cac;"})
* **Step 3: Make a decision**
    * [Reject $H_0$ and support $H_a$ if]{style="color: #6e8e13;"}
        * p-value < alpha
        * Test statistic more extreme than critical value
    * [Fail to reject $H_0$ and fail to support $H_a$ if]{style="color: #754cbc;"}
        * p-value > alpha
        * Test statistic less extreme than critical value
:::
:::

::::

## Step 1: Plan 

#### State the null and alternative [hypotheses]{style="color: #e93cac;"}

*You are interested in knowing whether immigrants (US residents born outside of the country) are different from the US population as a whole in terms of educational attainment.  You draw a random sample of 225 adult immigrants and find that their average level of education is 13.3 years.  Compare this to the statistics for the population of American adults which has an average education of 12.75 with a standard deviation of 4 years.  Use a .05 alpha level to test the statistical significance of the observed difference.*

:::: {.columns}

::: {.column width="30%"}

<br>

::: {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 275px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
$$
H_0: \mu_{immig} = 12.75
$$
:::

::: {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 275px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
$$
H_a: \mu_{immig} \ne 12.75
$$
:::

:::

::: {.column width="70%"}

:::

::::

::: {.fragment fragment-index=1 style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 750px; padding: 5px 5px 5px 5px; position: absolute; bottom: 150px; right: -75px; text-align: center;"}
Set up a test assuming that the null $H_0$ is true and see whether the facts of our sample contradict that assumption
:::

## Step 1: Plan 

#### Choose your [alpha]{style="color: #e93cac;"} level and find the [critical value]{style="color: #e93cac;"}

*You are interested in knowing whether immigrants (US residents born outside of the country) are different from the US population as a whole in terms of educational attainment.  You draw a random sample of 225 adult immigrants and find that their average level of education is 13.3 years.  Compare this to the statistics for the population of American adults which has an average education of 12.75 with a standard deviation of 4 years.  Use a .05 alpha level to test the statistical significance of the observed difference.*

:::: {.columns}

::: {.column width="30%"}

<br>

::: {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 275px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
$$
H_0: \mu_{immig} = 12.75
$$
:::

::: {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 275px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
$$
H_a: \mu_{immig} \ne 12.75
$$
:::

:::

::: {.column width="70%"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

z2 <- 2.241
z1 <- -2.241

ggplot(data = eq, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_lower, args = list(upper_bound = z1), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  stat_function(fun = funcShaded_upper, args = list(lower_bound = z2), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  theme(axis.text.x = element_text(size = 18)) +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = c(-1.96, 1.96), labels = c(expression(paste(alpha, "/ 2 = 0.250")), expression(paste(alpha, "/ 2 = 0.250")))) 
```
:::

::::

::: {style="background: black; color: white; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 150px; left: 325px; text-align: center"}
Normal<br>
distribution<br>
[$\alpha = 0.05$]{style="color: #e93cac;"}
:::

::: {.fragment fragment-index=1 style="width: 300px; position: absolute; bottom: 225px; right: -50px; text-align: center; font-size: 0.85em;border: 3px solid black;"}
So our sample result has to be at least [1.96]{style="color: #e93cac;"} standard errors away from what is assumed under $H_0$ for us to reject $H_0$
:::

::: {.fragment fragment-index=1 style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px; position: absolute; bottom: 75px; right: -75px; text-align: center"}
$H_a: \mu \ne 0$<br>
Critical value of<br>
[$z = \pm 1.96$]{style="color: #e93cac;"}
:::

## Step 2: Calculate 

#### Calculate [test statistic]{style="color: #e93cac;"} (and [p-value]{style="color: #e93cac;"})

*You are interested in knowing whether immigrants (US residents born outside of the country) are different from the US population as a whole in terms of educational attainment.  You draw a random sample of 225 adult immigrants and find that their average level of education is 13.3 years.  Compare this to the statistics for the population of American adults which has an average education of 12.75 with a standard deviation of 4 years.  Use a .05 alpha level to test the statistical significance of the observed difference.*

:::: {.columns}

::: {.column width="30%"}

<br>

::: {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 275px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
$$
H_0: \mu_{immig} = 12.75
$$
:::

::: {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 275px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
$$
H_a: \mu_{immig} \ne 12.75
$$
:::

:::

::: {.column width="40%"}

<br>

::: {.fragment fragment-index=1}
Figuring out how far the sample result is from $H_0$ and putting it in standard-error units
:::

::: {.fragment fragment-index=1 style="font-size: 1.25em"}
$$
\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{4}{\sqrt{225}} = 0.267
$$
:::
:::

::: {.column width="30%"}

<br>

::: {.fragment fragment-index=2 style="font-size: 1.5em; text-align: end"}
[$z$]{style="color: #e93cac;"} $= \frac{\bar{X} - \mu_0}{\sigma_{\bar{X}}}$

<br>

$\frac{13.3-12.75}{0.267} =$ [$2.060$]{style="color: #e93cac;"}
:::

:::

::::

::: {.fragment fragment-index=3 style="background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 800px; padding: 0px 0px 0px 0px; position: absolute; bottom: -15px; right: -75px; text-align: center; font-size: 0.85em"}
Mean education for immigrants is [2.06]{style="color: #e93cac;"} standard errors above the national average (assumed under $H_0$)
:::

## Step 3: Make a decision 

#### [Reject $H_0$ and support $H_a$]{style="color: #6e8e13;"}

*You are interested in knowing whether immigrants (US residents born outside of the country) are different from the US population as a whole in terms of educational attainment.  You draw a random sample of 225 adult immigrants and find that their average level of education is 13.3 years.  Compare this to the statistics for the population of American adults which has an average education of 12.75 with a standard deviation of 4 years.  Use a .05 alpha level to test the statistical significance of the observed difference.*

:::: {.columns}

::: {.column width="30%"}

<br>

::: {style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 275px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
$$
H_0: \mu_{immig} = 12.75
$$
:::

::: {style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 275px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
$$
H_a: \mu_{immig} \ne 12.75
$$
:::

:::

::: {.column width="70%"}

::: {.fragment fragment-index=1}
* Based on this evidence, it appears that the *population of immigrants have, on average, [more education]{.underline} than the national average*.
* The [observed difference]{.underline} **IS statistically significant**
:::

::: {style="border: 4px solid #6e8e13; border-radius: 15px; text-align: center"}
Since our [test statistic]{style="color: #e93cac;"} ([2.06]{style="color: #e93cac;"}) is more extreme than the [critical value]{style="color: #e93cac;"} ([1.96]{style="color: #e93cac;"}) we<br>[REJECT $H_0$, FIND EVIDENCE TO SUPPORT $H_A$]{style="color: #6e8e13; font-size: 1.25em"}
:::

:::

::::

# Break! {.section-title background-color="#2ad2c9"}

# t-distribution {.section-title background-color="#c5b4e3"}

## Inference with the t-distribution

### [Why use something other than the normal (z) distribution?]{style="font-size: 0.9em"}

::: {.fragment fragment-index=1}
#### TYPES OF INFERENCE SO FAR:
:::

:::: {.columns}

::: {.column width="50%"}

<br>

::: {.fragment fragment-index=1}
[Confidence intervals:]{.underline}
Assume our sample<br>of 100 UW students comes from a [population]{style="background: #ffc700"} with a [standard deviation of 8.0]{style="background: #ffc700"}, estimate the population mean…

<br>

[Hypothesis testing:]{.underline}
Say we know that the average study time for the [population]{style="background: #ffc700"} of college students in the country is 13 hrs/week, with a [standard deviation of 8.0]{style="background: #ffc700"}.  Do UW students really study more than the national average?
:::
:::

::: {.column width="50%"}
::: {.fragment fragment-index=2 style="font-size: 1.25em"}
These types of examples are [**UNREALISTIC**]{.underline} (or at least really rare) because **we rarely know the [population]{style="background: #ffc700"} standard deviation**.
:::

::: {style="font-size: 1.5em; position: absolute; top: 350px; right: 350px; text-align: center; color: #a68100"}
::: {.fragment .fade-in fragment-index=1}
::: {.fragment .shrink fragment-index=3}
::: {.fragment .semi-fade-out fragment-index=3}
$$
\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}
$$
:::
:::
:::
:::

::: {style="font-size: 1.5em; position: absolute; top: 350px; right: 100px; color: #e93cac"}
::: {.fragment .fade-in fragment-index=3 }
::: {.fragment .grow fragment-index=3 }
$$
s_{\bar{X}} = \frac{s}{\sqrt{n}}
$$
:::
:::
:::

:::

::::

::: {.fragment fragment-index=3 style="background: black; color: white; font-size: 1em; width: 500px; padding: 5px 5px 5px 5px; position: absolute; top: 195px; right: 25px; text-align: center"}
When the population standard deviation is unknown, use the [**SAMPLE standard deviation**]{.underline style="color: #e93cac"} to estimate the standard error used in inferences.
:::

::: {.fragment fragment-index=4 style="background: #e8e3d3; width: 500px; position: absolute; top: 223px; left: 0px;"}
[Confidence intervals:]{.underline}
You draw a sample of 100 UW students and find that the average study time is 14.5 hours/week with a [sample standard deviation of 8.25]{style="background: #e93cac"}, estimate the population mean.

<br>

[Hypothesis testing:]{.underline}
You draw a sample of 100 UW students and find that the average study time is 14.5 hours/week with a [sample standard deviation of 8.25]{style="background: #e93cac"}.  Test the hypothesis that UW students study more than the national average of 13 hours/week.

:::

::: {.fragment fragment-index=4 style="background: #e8e3d3; width: 500px; position: absolute; top: 150px; left: 0px;"}
#### MORE REALISTICS EXAMPLES:
:::

::: {.fragment fragment-index=5 style="position: absolute; bottom: 0px; right: 150px; border: 2px solid black; padding: 5px 5px 5px 5px;text-align: center "}
[[PROBLEM]{.underline}: Using sample statistics to make<br>two difference inferences]{style="font-size: .75em"} <br>
[$s_x \Rightarrow \sigma_x$]{style="font-size: 1.25em;"}
<br>
[$\bar{X} \Rightarrow \mu_x$]{style="font-size: 1.25em"}
<br>
[= INCREASED UNCERTAINTY]{style="background: #aadb1e;"}
:::

::: {.fragment fragment-index=6 style="position: absolute; bottom: 25px; right: -75px; background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 200px; padding: 5px 5px 5px 5px"}
This is especially problematic when the sample size is **small**!
:::

## Inference with the t-distribution

### [Why use something other than the normal (z) distribution?]{style="font-size: 0.9em"}

::: {style="font-size: 2.5em; text-align: center"}
Account for the [**extra uncertainty**]{.underline} by assuming that the sampling distribution follows a [t-distribution]{.underline style="color: #e93cac"} instead of a normal (z) distribution.
:::

::: {.fragment fragment-index=1 style="position: absolute; bottom: 25px; left: 25px; background: #2ad2c9; border: 4px solid #1b8883; border-radius: 15px; width: 450px; padding: 5px 5px 5px 5px; text-align: center"}
Using the t-distribution tends to give more [conservative]{.underline style="color: #e93cac"} inferences (e.g., wider confidence intervals, more extreme critical values)
:::

::: {.fragment fragment-index=2 style="position: absolute; bottom: 50px; right: 25px; background: #ffc700; border: 4px solid #a68100; border-radius: 15px; width: 450px; padding: 5px 5px 5px 5px; text-align: center"}
Correction is most dramatic when the [sample size is small]{.underline style="color: #e93cac"}

:::

## Inference with the t-distribution

### What is the t-distribution?

::: incremental
* t-distribution is a family of distributions (several different shapes)
* t-distribution is *similar* to Normal
    * Symmetric		 
    * Single peak
    * Centered on a mean/median/mode of 0
* t-distribution is *different* from Normal in that it tends to  
    * be flatter
    * be more spread out
    * have a higher proportion of cases out on the tails
:::

::: {.fragment style="font-size: 2em; text-align: center"}
How different [t]{style="color: #e93cac"} is from Normal depends on the [degrees of freedom]{.underline style="color: #e93cac"}
:::

## Inference with the t-distribution

:::: {.columns}

::: {.column width="40%"}
::: {style="font-size: 2em; text-align: center"}
> [**Degrees of freedom (df)**]{style="color: #e93cac"}<br>
The number of scores that are free to vary in the calculation of a statistic
:::
:::

::: {.column width="60%"}
::: {.fragment style="font-size: 1.25em"}
#### Example

[Q: If a sample of $n = 5$ has a mean of 3, how many scores are free to vary?]{style="color: #a68100"}
:::

<br>

::: {.fragment style="font-size: 1.75em; text-align: center"}
___  + ___ + ___ + ___ + ___ = 15
:::

::: {.fragment style="color: #e93cac; font-size: 1.75em; text-align: center; position: absolute; top: 257px; right: 545px"}
2
:::

::: {.fragment style="color: #e93cac; font-size: 1.75em; text-align: center; position: absolute; top: 257px; right: 445px"}
1
:::

::: {.fragment style="color: #e93cac; font-size: 1.75em; text-align: center; position: absolute; top: 257px; right: 330px"}
7
:::

::: {.fragment style="color: #e93cac; font-size: 1.75em; text-align: center; position: absolute; top: 257px; right: 230px"}
2
:::

<br>

::: {.fragment style="font-size: 1.25em; color: #1b8883"}
A: [$n-1=4$]{.center} <br>
Once you know the first four numbers, there is only one value that the fifth could take to produce a mean of $3$.
:::

:::

::::

::: {.fragment style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 400px; padding: 5px 5px 5px 5px; font-size: 1em; text-align: center; position: absolute; top: 340px; right: 125px"}
df for calculation of a mean = $n-1$
:::

## Inference with the t-distribution

```{r}
#| echo: false
#| fig-width: 10
#| fig-height: 6
#| fig-align: center

tdist <- ggplot(data.frame(x = c(-10, 10)), aes(x = x)) + 
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), linewidth = 1, color = "black") +
  annotate(geom = "text", x = 2, y = 0.4, color = "black", label = "Normal") + 
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 1") + 
  stat_function(fun = dt, args = list(df = 1), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 2") + 
  stat_function(fun = dt, args = list(df = 2), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 3") + 
  stat_function(fun = dt, args = list(df = 3), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 4") + 
  stat_function(fun = dt, args = list(df = 4), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 5") + 
  stat_function(fun = dt, args = list(df = 5), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 6") + 
  stat_function(fun = dt, args = list(df = 6), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 7") + 
  stat_function(fun = dt, args = list(df = 7), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 8") + 
  stat_function(fun = dt, args = list(df = 8), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 9") + 
  stat_function(fun = dt, args = list(df = 9), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 10") + 
  stat_function(fun = dt, args = list(df = 10), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 20") + 
  stat_function(fun = dt, args = list(df = 20), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 30") + 
  stat_function(fun = dt, args = list(df = 30), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 40") + 
  stat_function(fun = dt, args = list(df = 40), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 50") + 
  stat_function(fun = dt, args = list(df = 50), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 60") + 
  stat_function(fun = dt, args = list(df = 60), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 70") + 
  stat_function(fun = dt, args = list(df = 70), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 80") + 
  stat_function(fun = dt, args = list(df = 80), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 90") + 
  stat_function(fun = dt, args = list(df = 90), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 100") + 
  stat_function(fun = dt, args = list(df = 100), linewidth = 0.5, color = "#e93cac") +
  #annotate(geom = "text", x = 3.5, y = 0.3, color = "#e93cac", label = "t, df = 1000") + 
  stat_function(fun = dt, args = list(df = 1000), linewidth = 0.5, color = "#e93cac") +
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = c(-10, -5, 0, 5, 10)) + 
  transition_layers(layer_length = 5, transition_length = 1,
                    from_blank = FALSE, keep_layers = c(Inf, Inf, Inf, Inf, rep(0, 20)), 
                    layer_names = c("", "", "", "", "t, df = 1", "t, df = 2", "t, df = 3", "t, df = 4", "t, df = 5", "t, df = 6", "t, df = 7", 
                                    "t, df = 8", "t, df = 9", "t, df = 10", "t, df = 20", "t, df = 30", "t, df = 40", "t, df = 50", 
                                    "t, df = 60", "t, df = 70", "t, df = 80", "t, df = 90", "t, df = 100", "t, df = 1000")) +
  enter_fade() + 
  exit_fade() + 
  labs(title = "Comparison of standard normal and student t distributions", subtitle = "{closest_layer}") + 
  theme(plot.subtitle = element_text(color = "#e93cac", size = 18, vjust = 5, hjust = 0.35))

animate(plot = tdist, nframes = 100, fps = 5, end_pause = 10)
```

::: {.fragment style="position: absolute; top: 190px; right: -275px"}
| t-distribution  | critical value  |
|:------|:------:|
| df = 3  | $\pm3.182$   |
| df = 30   | $\pm2.042$   |
| df = 100 | $\pm1.984$   |
| df = 1000 | $\pm1.962$   |

: For 95% confidence level<br>($\alpha = 0.05$, two-sided) {tbl-colwidths="[20,25]"}
:::

::: {.fragment style="border: 3px solid #e93cac; border-radius: 15px; width: 450px; padding: 5px 5px 5px 5px; position: absolute; bottom: 200px; left: -50px"}
**Notice**: Tests with the [t-distribution]{style="color: #e93cac"} are more conservative (wider confidence intervals, harder to reject H0) than with normal (critical value: **$\pm1.960$**) and results are [especially conservative]{.underline} when the [sample size (df) is small]{.underline}.
:::

## More realistic example

### Estimation: Confidence interval

*You draw a sample of 100 UW students and find that the average study time is 14.5 hours/week with a [sample standard deviation of 8.25]{style="color: #e93cac"}. Estimate the population mean.*

<br>

:::: {.columns}

::: {.column width="40%"}

::: {.fragment .fade-in fragment-index=3}
::: {.fragment .grow fragment-index=3 style="font-size: 1em; text-align: center;"}
::: {.fragment .fade-out fragment-index=6}
$$
\text{Confidence interval} = 
$$


[$$
\bar{X} \pm t(\frac{s_x}{\sqrt{n}})
$$]{style="color: #e93cac"}
:::
:::
:::

<br>

::: {.fragment fragment-index=5}
$$
\text{95% C.I.} = 14.5 \pm 1.984(0.825)
$$
$$
\text{        } = 14.5 \pm 1.6368
$$
:::


:::

::: {.column width="60%"}

::: {.fragment fragment-index=1}
* Population standard deviation is unknown
:::

::: {.fragment fragment-index=2}
* Use the sample standard deviation to estimate the standard error

$$
s_\bar{X} = \frac{s_x}{\sqrt{n}} = \frac{8.25}{\sqrt{100}} = 0.825
$$
:::


::: {.fragment fragment-index=4}
* Use the t-distribution^[[Table](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm) from your textbook or an [online calculator](https://goodcalculators.com/student-t-value-calculator/)] with $df = n - 1$
:::

::: {.fragment fragment-index=4}
[$df = 100 - 1 = 99$]{.center}
:::


:::

::::

::: {.fragment fragment-index=6 style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 400px; padding: 5px 5px 5px 5px; position: absolute; top: 250px; left: 00px; text-align: center"}
We are [95% confident]{.underline} that the average number of hours studied for the [population]{.underline} of UW students is between [12.86 to 16.14]{.underline} hours
:::

## More realistic example

### Hypothesis testing

*You draw a sample of 100 UW students and find that the average study time is 14.5 hours/week with a [sample standard deviation of 8.25]{style="color: #e93cac"}. Test the hypothesis that UW students study more than the national average of 13 hours/week.*

:::: {.columns}

::: {.column width="40%"}
::: {.fragment fragment-index=1}
[$H_0: \mu_{UW} = 13$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1em"} [$H_a: \mu_{UW} \gt 13$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1em"}
:::
<br>

::: {.fragment fragment-index=2 style="text-align: center;"}
Critical value of t?
:::

<br>


:::

::: {.column width="60%"}

::: {.fragment fragment-index=1}
* Population standard deviation is unknown



* Use the sample standard deviation to estimate the standard error

$$
s_\bar{X} = \frac{s_x}{\sqrt{n}} = \frac{8.25}{\sqrt{100}} = 0.825
$$




* Use the t-distribution^[[Table](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm) from your textbook or an [online calculator](https://goodcalculators.com/student-t-value-calculator/)] with $df = n - 1$



[$df = 100 - 1 = 99$]{.center}
:::


:::

::::

## More realistic example

### Hypothesis testing

*You draw a sample of 100 UW students and find that the average study time is 14.5 hours/week with a [sample standard deviation of 8.25]{style="color: #e93cac"}. Test the hypothesis that UW students study more than the national average of 13 hours/week.*

:::: {.columns}

::: {.column width="40%"}

[$H_0: \mu_{UW} = 13$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1em"} [$H_a: \mu_{UW} \gt 13$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1em"}

<br>


::: {style="text-align: center;"}
Critical value of t = [1.660]{style="color: #e93cac"}
:::


<br>

::: {.fragment fragment-index=1 style="font-size: 1em"}
Test statistic from the sample:<br>
:::

::: {.fragment fragment-index=1 style="font-size: 1.25em; text-align: center"}
$t = \frac{\bar{X}-\mu_0}{s_\bar{X}} = \frac{14.5 - 13}{0.825} =$ [$1.818$]{style="color: #1b8883"}
:::


:::

::: {.column width="60%"}

::: {.fragment .fade-out fragment-index=2}
* Population standard deviation is unknown



* Use the sample standard deviation to estimate the standard error

$$
s_\bar{X} = \frac{s_x}{\sqrt{n}} = \frac{8.25}{\sqrt{100}} = 0.825
$$




* Use the t-distribution^[[Table](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm) from your textbook or an [online calculator](https://goodcalculators.com/student-t-value-calculator/)] with $df = n - 1$



[$df = 100 - 1 = 99$]{.center}
:::


:::

::::

::: {.fragment fragment-index=2 style="border: 4px solid black; border-radius: 15px; width: 550px; padding: 5px 5px 5px 5px; position: absolute; top: 350px; right: 0px; text-align: center"}
Since [obtained t]{style="color: #1b8883"} is more extreme than [critical value]{style="color: #e93cac"}, reject $H_0$ and support the claim that the population of UW students really do study more than the national average.
:::

## Practice

:::: {.columns}

::: {.column width="45%"}
#### Estimation: Confidence interval

*In a random sample of 121 UW students, the mean number of visits to family in the past six months was 5.5 with a  standard deviation of 0.9.  Calculate a 90% confidence interval for the average number of visits in the population.*

::: {.fragment}
[**STEPS**:]{.underline style="background: #c5b4e3"}

1. Decide on a confidence level and corresponding [t-score]{style="color: #e93cac"}
2. Calculate the standard error (using **sample** standard deviation)
3. Calculate the margin of error
4. Calculate the confidence interval
5. Interpret the results
:::
:::

::: {.column width="55%"}
#### Hypothesis test
*You want to know whether high school students are different than the national average (µ=220) in terms of the number of Facebook friends.  A random sample of 30 high school students shows a mean number of Facebook friends of 245 with a standard deviation of 90.  Is this difference from the national average statistically significant at the .01 level?*

::: {.fragment}
[**STEPS**:]{.underline style="background: #c5b4e3"}

1a. State the null and alternative hypotheses <br>
1b. Choose your alpha level and find the critical value <br>
2. Calculate the test statistic ([t-score]{style="color: #e93cac"}) and p-value <br>
3. Make a decision (Reject or fail to reject the null hypothesis ($H_0$) and support or fail to support the alternative hypothesis $H_a$)
:::
:::

::::

## Practice {visibility="hidden"}

#### Estimation: Confidence interval

*In a random sample of 121 UW students, the mean number of visits to family in the past six months was 5.5 with a  standard deviation of 0.9.  Calculate a 90% confidence interval for the average number of visits in the population.*

<br>

:::: {.columns}

::: {.column width="40%"}

::: {.fragment .fade-in fragment-index=3}
::: {.fragment .grow fragment-index=3 style="font-size: 1em; text-align: center;"}
::: {.fragment .fade-out fragment-index=6}
$$
\text{Confidence interval} = 
$$


[$$
\bar{X} \pm t(\frac{s_x}{\sqrt{n}})
$$]{style="color: #e93cac"}
:::
:::
:::

<br>

::: {.fragment fragment-index=5}
$$
\text{90% C.I.} = 5.5 \pm 1.66(0.082)
$$
$$
\text{        } = 5.5 \pm 0.136
$$
:::


:::

::: {.column width="60%"}

::: {.fragment fragment-index=1}
* Population standard deviation is unknown
:::

::: {.fragment fragment-index=2}
* Use the sample standard deviation to estimate the standard error

$$
s_\bar{X} = \frac{s_x}{\sqrt{n}} = \frac{0.9}{\sqrt{121}} = 0.082
$$
:::


::: {.fragment fragment-index=4}
* Use the t-distribution^[[Table](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm) from your textbook or an [online calculator](https://goodcalculators.com/student-t-value-calculator/)] with $df = n - 1$
:::

::: {.fragment fragment-index=4}
[$df = 121 - 1 = 120$]{.center}
:::


:::

::::

::: {.fragment fragment-index=6 style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 400px; padding: 5px 5px 5px 5px; position: absolute; top: 250px; left: 00px; text-align: center"}
We are [90% confident]{.underline} that the average number of visits to family for the [population]{.underline} of UW students is between [5.364 to 5.636]{.underline} hours
:::

## Practice {visibility="hidden"}

#### Hypothesis test

*You want to know whether high school students are different than the national average (µ=220) in terms of the number of Facebook friends.  A random sample of 30 high school students shows a mean number of Facebook friends of 245 with a standard deviation of 90.  Is this difference from the national average statistically significant at the .01 level?*

:::: {.columns}

::: {.column width="40%"}
::: {.fragment fragment-index=1}
[$H_0: \mu_{HS} = 220$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1em"} [$H_a: \mu_{HS} \ne 220$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1em"}
:::
<br>

::: {.fragment fragment-index=2 style="text-align: center;"}
Critical value of t?
:::

<br>


:::

::: {.column width="60%"}

::: {.fragment fragment-index=1}
* Population standard deviation is unknown



* Use the sample standard deviation to estimate the standard error

$$
s_\bar{X} = \frac{s_x}{\sqrt{n}} = \frac{90}{\sqrt{30}} = 16.432
$$




* Use the t-distribution^[[Table](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm) from your textbook or an [online calculator](https://goodcalculators.com/student-t-value-calculator/)] with $df = n - 1$



[$df = 30 - 1 = 29$]{.center}
:::


:::

::::

## Practice {visibility="hidden"}

#### Hypothesis test

*You want to know whether high school students are different than the national average (µ=220) in terms of the number of Facebook friends.  A random sample of 30 high school students shows a mean number of Facebook friends of 245 with a standard deviation of 90.  Is this difference from the national average statistically significant at the .01 level?*

:::: {.columns}

::: {.column width="40%"}

[$H_0: \mu_{HS} = 220$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1em"} [$H_a: \mu_{HS} \ne 220$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1em"}

<br>


::: {style="text-align: center;"}
Critical value of t = [2.756]{style="color: #e93cac"}
:::


<br>

::: {.fragment fragment-index=1 style="font-size: 1em"}
Test statistic from the sample:<br>
:::

::: {.fragment fragment-index=1 style="font-size: 1.25em; text-align: center"}
$t = \frac{\bar{X}-\mu_0}{s_\bar{X}} = \frac{245 - 220}{16.432} =$ [$1.521$]{style="color: #1b8883"}
:::


:::

::: {.column width="60%"}

::: {.fragment .fade-out fragment-index=2}
* Population standard deviation is unknown



* Use the sample standard deviation to estimate the standard error

$$
s_\bar{X} = \frac{s_x}{\sqrt{n}} = \frac{90}{\sqrt{30}} = 16.432
$$




* Use the t-distribution^[[Table](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm) from your textbook or an [online calculator](https://goodcalculators.com/student-t-value-calculator/)] with $df = n - 1$



[$df = 30 - 1 = 29$]{.center}
:::


:::

::::

::: {.fragment fragment-index=2 style="border: 4px solid black; border-radius: 15px; width: 550px; padding: 5px 5px 5px 5px; position: absolute; top: 350px; right: 0px; text-align: center"}
Since [obtained t]{style="color: #1b8883"} is **NOT** more extreme than [critical value]{style="color: #e93cac"}, we **FAIL TO REJECT** $H_0$ that the average number of FB friends in the high school population is the same as the national average. 
:::

# Hypothesis testing for two samples {.section-title background-color="#c5b4e3"}

## Where are we? 

::: incremental
* [**Inference**]{.underline}: Drawing conclusions about populations based on information drawn from samples
* [**Inferences so far**]{.underline}:
    * Confidence intervals to estimate a population mean or proportion based on the results from a SINGLE SAMPLE
    * Hypothesis tests / tests of significance for a SINGLE SAMPLE:
        * Comparing our SINGLE SAMPLE result to some known benchmark
            * With and without *knowing* the standard deviation of the population of interest
        * [NOW: drawing conclusions about the difference between TWO unknown populations based on information from TWO samples]{style="background: #ffc700; color: #754cbc"}
:::

## Two-sample hypothesis test

::: fragment
#### Step 1a: State the null and alternative hypotheses
:::

*We want to know if UW students differ from WSU students in terms of average study time.  We draw a random sample of 100 UW students and find an average study time of 14.5 hours per week with a standard deviation of 8.25.  In contrast, our random sample of 81 WSU students has an average study time of 12.5 hours per week with a standard deviation of 7.0.  Use a .05 alpha level to test the statistical significance of the observed difference between means.*

:::: {.columns}

::: {.column width="30%"}
::: {.fragment}
[$H_0: \mu_{UW} = \mu_{WSU}$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"} 
<br>
<br>
<br>
<br>
<br>
<br>
[$H_a: \mu_{UW} \ne \mu_{WSU}$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
:::
:::

::: {.column width="30%"}
::: {.fragment}
[$H_0: \mu_{UW} - \mu_{WSU} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"} 
<br>
<br>
<br>
<br>
<br>
<br>
[$H_a: \mu_{UW} - \mu_{WSU} \ne 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
:::
:::

::: {.column width="40%"}
::: {.fragment style="border: 4px solid #754cbc; border-radius: 15px; padding: 1px 1px 1px 1px; text-align: center; width: 400px"}
Observed difference between sample means reflects chance sampling error.
:::

::: {.fragment style="border: 4px solid #6e8e13; border-radius: 15px; padding: 1px 1px 1px 1px; text-align: center; width: 400px"}
Observed difference b/w sample means reflects a real difference b/w population means
:::
:::

::::

## Two-sample hypothesis test

### Other possible hypotheses

:::: {.columns}

::: {.fragment .column width="50%" style="text-align: center"}
#### [Two-sided]{.underline}

*Question just asks about any difference*

<br>

[$H_a: \mu_{1} \ne \mu_{2}$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}


::: {style="font-size: 2em;"}
↓
:::

[$H_a: \mu_{1} - \mu_{2} \ne 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"}
:::

::: {.fragment .column width="60%" style="text-align: center"}
#### [One-sided]{.underline}

*Question implies a direction of difference*

<br>

:::: {.columns}

::: {.fragment .column width="30%"}
[$H_a: \mu_{1} \gt \mu_{2}$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em; position: absolute; top: 275px; right: 275px"}


::: {style="font-size: 2em; position: absolute; top: 330px; right: 350px"}
↓
:::

[$H_a: \mu_{1} - \mu_{2} \gt 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em; position: absolute; bottom: 225px; right: 250px"}
:::
:::

::: {.fragment .column width="30%"}
[$H_a: \mu_{1} \lt \mu_{2}$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em; position: absolute; top: 275px; right: -25px"}


::: {style="font-size: 2em; position: absolute; top: 330px; right: 50px"}
↓
:::

[$H_a: \mu_{1} - \mu_{2} \lt 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em; position: absolute; bottom: 225px; right: -50px"}
:::

::::


::::

::: {.fragment style="width: 400px; padding: 5px 5px 5px 5px; position: absolute; top: 330px; left: 275px; text-align: center; font-size: 0.75em"}
Can restate any in terms of [differences]{.underline} between  population means
:::

<br>

::: {.fragment style="text-align: center;"}
Note: all of these hypothesize a [real difference]{.underline} between [population]{.underline} means
:::

::: {.fragment style="text-align: center;"}
All are contradicted by the same null hypothesis

[$H_0: \mu_{1} = \mu_{2}$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"} [→]{style="font-size: 2em"} [$H_0: \mu_{1} - \mu_{2} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; text-align: center; font-size: 1.25em"} 
:::

## Two-sample hypothesis test

#### Step 1a: State the null and alternative hypotheses

::: {.fragment .fade-out fragment-index=2}
*We want to know if UW students differ from WSU students in terms of average study time.  We draw a random sample of 100 UW students and find an average study time of 14.5 hours per week with a standard deviation of 8.25.  In contrast, our random sample of 81 WSU students has an average study time of 12.5 hours per week with a standard deviation of 7.0.  Use a .05 alpha level to test the statistical significance of the observed difference between means.*
:::

::: {.center}
[$H_0: \mu_{UW} - \mu_{WSU} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em"} [$H_a: \mu_{UW} - \mu_{WSU} \ne 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px;font-size: 1.25em"}
:::

<br>

::: {.fragment fragment-index=1}
* Set up a test assuming that the null ($H_0$) is true and see whether the facts of our samples contradict that assumption.
* Key question: How likely is it that we would observe a sample difference this big <br>
($14.5-12.5 = 2 \text{ hrs}$) if the null ($H_0$) were true?
    * [If very unlikely, we will reject $H_0$ and support $H_a$]{style="color: #6e8e13"}
    * [If not very unlikely, we will fail to reject $H_0$]{style="color: #754cbc"}
:::

::: {.fragment fragment-index=2 style="background: #e8e3d3; position: absolute; top: 125px; left: 75px"}
* Have to think about **probability** of receiving our sample result (difference) if $H_0$ were true
    * Have to think about the **SAMPLING DISTRIBUTION** of all possible sample results
:::

## Sampling theory

#### Hypothesis test for difference between means 

[Sampling Distribution for the difference between means]{.underline}

A theoretical probability distribution that would be obtained by calculating all of the possible mean differences ($\bar{X_1}-\bar{X_2}$) for [all possible pairs]{.underline} of random, independent samples of size $n_1$ and $n_2$ drawn from two populations.


---

[*The DIFFERENCES between sample means drawn from every possible PAIR of samples create a SAMPLING DISTRIBUTION [OF DIFFERENCES BETWEEN (SAMPLE) MEANS]{.underline}*]{.center}

::: {.incremental style="color: #e93cac; position: absolute; top 200px; left: 0px; font-size: 1.25em"}
* $\bar{X}_{UW1} - \bar{X}_{WSU1} = \bar{X}_{diff1}$ <br>
* $\bar{X}_{UW2} - \bar{X}_{WSU2} = \bar{X}_{diff2}$ <br>
* $\bar{X}_{UW3} - \bar{X}_{WSU3} = \bar{X}_{diff3}$ <br>
* . . . 
:::

```{r}
#| echo: false
#| fig-width: 16
#| fig-height: 12
#| fig-align: center

set.seed(711)
samples <- c(rep(0, 12), rep(-0.375, 11), rep(0.375, 11), rep(-0.750, 10), rep(0.750, 10), rep(-1.125, 8), rep(1.125, 8), rep(-1.500, 6), rep(1.500, 6), rep(-1.875, 4), rep(1.875, 4), rep(-2.250, 3), rep(2.250, 3), rep(-2.625, 1), rep(2.625, 1), rep(-3, 1), 
rep(3, 1)) 

index <- seq(1:length(samples))
sample_samples <- sample(samples, 100)
df <- tibble(value = sample_samples, index = index)

bin_width <- 0.375

count_data <- # some minor data transformation
  df %>%
  mutate(x = plyr::round_any(value, bin_width)) %>%
  group_by(x) %>%
  mutate(y = seq_along(x))

plot2 <- 
  ggplot(count_data) +
  geom_ellipse(aes(group = index, x0 = x, y0 = y, a = bin_width/2, b = 0.5, angle = 0), fill = NA) +
  #annotate(geom = text, label = expression(bar("X")["1]"), x = 0, 1) +
  # i hate the code below but couldn't figure out how to make a label variable with bquote or expression and needed to move on
  geom_text(data = count_data[1, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff1]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[2, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff2]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[3, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff3]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[4, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff4]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[5, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff5]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[6, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff6]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[7, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff7]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[8, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff8]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[9, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff9]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[10, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff10]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[11, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff11]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[12, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff12]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[13, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff13]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[14, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff14]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[15, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff15]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[16, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff16]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[17, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff17]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[18, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff18]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[19, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff19]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[20, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff20]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[21, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff21]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[22, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff22]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[23, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff23]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[24, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff24]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[25, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff25]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[26, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff26]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[27, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff27]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[28, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff28]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[29, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff29]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[30, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff30]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[31, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff31]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[32, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff32]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[33, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff33]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[34, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff34]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[35, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff35]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[36, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff36]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[37, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff37]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[38, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff38]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[39, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff39]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[40, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff40]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[41, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff41]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[42, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff42]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[43, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff43]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[44, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff44]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[45, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff45]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[46, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff46]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[47, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff47]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[48, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff48]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[49, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff49]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[50, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff50]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[51, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff51]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[52, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff52]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[53, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff53]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[54, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff54]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[55, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff55]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[56, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff56]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[57, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff57]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[58, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff58]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[59, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff59]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[60, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff60]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[61, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff61]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[62, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff62]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[63, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff63]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[64, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff64]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[65, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff65]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[66, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff66]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[67, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff67]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[68, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff68]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[69, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff69]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[70, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff70]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[71, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff71]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[72, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff72]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[73, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff73]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[74, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff74]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[75, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff75]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[76, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff76]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[77, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff77]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[78, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff78]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[79, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff79]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[80, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff80]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[81, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff81]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[82, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff82]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[83, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff83]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[84, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff84]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[85, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff85]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[86, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff86]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[87, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff87]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[88, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff88]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[89, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff89]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[90, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff90]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[91, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff91]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[92, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff92]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[93, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff93]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[94, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff94]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[95, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff95]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[96, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff96]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[97, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff97]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[98, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff98]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[99, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff99]))), parse = TRUE, color = "#e93cac", size = 6, fontface = "bold") +
  geom_text(data = count_data[100, ], aes(x = x, y = y, label = deparse(bquote(bar(X)[diff100]))), parse = TRUE, , color = "#e93cac", size = 6, fontface = "bold") +
  coord_equal(bin_width) + # to make the dots look nice and round
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = mu, color = "black") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL, limits = c(0, 13)) + scale_x_continuous(name = NULL, limits = c(-3.5, 3.5), breaks = NULL) + 
  annotate("label", x = 0, y = 0, label = "mu[x]", parse = TRUE, size = 12, color = "#690c48", fill = "#e93cac")

samples2 <- dnorm(c(seq(from = -3, to = 3, by = 0.375)), mean = mu, sd = sigma) * 30
count_data2 <- tibble(x = seq(from = -3, to = 3, by = 0.375), y = samples2)

plot2 + geom_freqpoly(data = count_data2, aes(x = x, y = y), stat = "smooth", position = position_nudge(y = 1.25), linewidth = 1.5, color = "#690c48")

```

## Sampling theory

#### Hypothesis test for difference between means 

[Characteristics of the Sampling Distribution for Difference between Two Means:]{.underline}

::: incremental
* IF the random samples are [independently drawn]{.underline} AND the [sample sizes are large]{.underline}<br>($n_1 + n_2 > 100$) then:
* The sampling distribution of differences between means would be NORMAL  
    * (but use the t-distribution when population standard deviations are unknown)
* The MEAN of this distribution would equal the real difference between the population means  

[$\mu_{\bar{X_1} - \bar{X_2}} = \mu_1 - \mu_2$]{.center .fragment style="font-size: 1.5em"}

* The STANDARD ERROR of the sampling distribution of differences would be  

[$\sigma_{\bar{X_1} - \bar{X_2}} = \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$]{.fragment style="font-size: 1.5em"} &emsp;&emsp;&emsp;&emsp;&emsp; [→]{.fragment style="font-size: 2em"} &emsp;&emsp;&emsp;&emsp;&emsp; [$s_{\bar{X_1} - \bar{X_2}} = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}$]{.fragment style="font-size: 1.5em"}

:::

::: {.fragment style="position: absolute; bottom: 10px; left: 425px; color: #754cbc; background: #c5b4e3"}
**INFERENCE**
:::

## Two-sample hypothesis test

#### Step 1b: Choose your alpha level and find the critical value

*We want to know if UW students [**differ**]{style="color: #1b8883;"} from WSU students in terms of average study time.  We draw a random sample of [**100**]{style="color: #a68100;"} UW students and find an average study time of 14.5 hours per week with a standard deviation of 8.25.  In contrast, our random sample of [**81**]{style="color: #a68100;"} WSU students has an average study time of 12.5 hours per week with a standard deviation of 7.0.  Use a [**.05 alpha level**]{style="color: #e93cac;"} to test the statistical significance of the observed difference between means.*

::: {.center}
[$H_0: \mu_{UW} - \mu_{WSU} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em"} [$H_a: \mu_{UW} - \mu_{WSU} \ne 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px;font-size: 1.25em"}
:::

<br>

:::: {.columns}

::: {.column width="30%"}
::: {.fragment .fade-out fragment-index=6}
[$\alpha = 0.05$ ]{.fragment fragment-index=1 style="color: #e93cac; border: 3px solid #e93cac; border-radius: 15px; padding: 5px 5px 5px 5px; width: 100px"} 
<br>
<br>
[Two-sided text]{.fragment fragment-index=2 style="color: #1b8883; border: 3px solid #1b8883; border-radius: 15px; padding: 5px 5px 5px 5px; width: 150px"}
:::
:::

::: {.column width="70%"}
::: {.fragment fragment-index=3 style="text-align: center"}
Because population standard deviations are unknown, use **t-distribution**^[[Table](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm) from your textbook<br>or an [online calculator](https://goodcalculators.com/student-t-value-calculator/)]
:::

::: {.fragment fragment-index=4 style="color: #a68100; border: 3px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; width: 310px"}
$df_1= n_1-1 = 100-1 = 99$
$df_2= n_2-1 = 81-1 = 80$
:::

[←]{.fragment fragment-index=5 style="font-size: 2em; position: absolute; bottom: 40px; right: 340px"} 

::: {.fragment fragment-index=5 style="background: #ffc700; border: 3px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; width: 350px; position: absolute; bottom: 0px; right: -25px; text-align: center"}
::: {.fragment .fade-out fragment-index=6}
Use the smaller of the two df’s to create a more conservative test! 
:::
:::

::: {.fragment fragment-index=6 style="background: #ffc700; border: 3px solid #a68100; border-radius: 15px; padding: 5px 5px 5px 5px; width: 350px; position: absolute; bottom: 0px; right: -25px; text-align: center; font-size: 0.85em"}
Our sample result has to be at least [1.99 standard errors]{style="background: #e93cac;"} away from the null hypothesis for us to reject the null hypothesis
:::

:::

::::

::: {.fragment fragment-index=6 style="position: absolute; bottom: 75px; left: -60px"}
```{r}
#| echo: false
#| fig-width: 4
#| fig-height: 2
#| fig-align: center

z2 <- 2.241
z1 <- -2.241

ggplot(data = eq, aes(x = x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = sigma), linewidth = 1) + 
  stat_function(fun = funcShaded_lower, args = list(upper_bound = z1), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  stat_function(fun = funcShaded_upper, args = list(lower_bound = z2), 
                  geom = "area", fill = "#a68100", alpha = .75) +
  geom_hline(yintercept = 0, color = "black") + geom_vline(xintercept = 0, color = "darkgray") + 
  theme_tufte() +
  scale_y_continuous(name = NULL, breaks = NULL) + scale_x_continuous(name = NULL, breaks = NULL) 
```
:::

## Two-sample hypothesis test

#### Step 2: Calculate the test statistic ([t-score]{style="color: #e93cac"}) and p-value <br>

*We want to know if UW students differ from WSU students in terms of average study time.  We draw a random sample of 100 UW students and find an average study time of 14.5 hours per week with a standard deviation of 8.25.  In contrast, our random sample of 81 WSU students has an average study time of 12.5 hours per week with a standard deviation of 7.0.  Use a .05 alpha level to test the statistical significance of the observed difference between means.*

::: {.center}
[$H_0: \mu_{UW} - \mu_{WSU} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em"} [$H_a: \mu_{UW} - \mu_{WSU} \ne 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px;font-size: 1.25em"}
:::

<br>

::: {.fragment style="text-align: center"}
Figuring out how far the sample result is from $H_0$<br>and putting it in standard-error units
:::

<br>

::: {.fragment style="font-size: 2em; text-align: center"}
$t = \frac{(\bar{X_1}-\bar{X_2})-0}{s_{\bar{X_1}}-s_{\bar{X_2}}}$
:::

## Two-sample hypothesis test

#### Step 2: Calculate the test statistic ([t-score]{style="color: #e93cac"}) and p-value <br>

*We want to know if UW students differ from WSU students in terms of average study time.  We draw a random sample of 100 UW students and find an average study time of 14.5 hours per week with a standard deviation of 8.25.  In contrast, our random sample of 81 WSU students has an average study time of 12.5 hours per week with a standard deviation of 7.0.  Use a .05 alpha level to test the statistical significance of the observed difference between means.*

::: {.center}
[$H_0: \mu_{UW} - \mu_{WSU} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em"} [$H_a: \mu_{UW} - \mu_{WSU} \ne 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px;font-size: 1.25em"}
:::

<br>

::: {style="text-align: center; color: #1b8883"}
Observed sample result<br>(difference between means)
:::

<br>

::: {style="font-size: 2em; text-align: center"}
$t = \frac{(\bar{X_1}-\bar{X_2})-0}{s_{\bar{X_1}}-s_{\bar{X_2}}}$
:::

::: {style="border: 3px solid #1b8883; width: 125px; height: 45px; position: absolute; bottom: 72px; left: 475px"}
:::

## Two-sample hypothesis test

#### Step 2: Calculate the test statistic ([t-score]{style="color: #e93cac"}) and p-value <br>

*We want to know if UW students differ from WSU students in terms of average study time.  We draw a random sample of 100 UW students and find an average study time of 14.5 hours per week with a standard deviation of 8.25.  In contrast, our random sample of 81 WSU students has an average study time of 12.5 hours per week with a standard deviation of 7.0.  Use a .05 alpha level to test the statistical significance of the observed difference between means.*

::: {.center}
[$H_0: \mu_{UW} - \mu_{WSU} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em"} [$H_a: \mu_{UW} - \mu_{WSU} \ne 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px;font-size: 1.25em"}
:::

<br>

::: {style="text-align: center; color: #754cbc"}
Difference observed under<br>the null hypotheses
:::

<br>

::: {style="font-size: 2em; text-align: center"}
$t = \frac{(\bar{X_1}-\bar{X_2})-0}{s_{\bar{X_1}}-s_{\bar{X_2}}}$
:::

::: {style="border: 3px solid #754cbc; width: 30px; height: 45px; position: absolute; bottom: 75px; left: 620px"}
:::

## Two-sample hypothesis test

#### Step 2: Calculate the test statistic ([t-score]{style="color: #e93cac"}) and p-value <br>

*We want to know if UW students differ from WSU students in terms of average study time.  We draw a random sample of 100 UW students and find an average study time of 14.5 hours per week with a standard deviation of 8.25.  In contrast, our random sample of 81 WSU students has an average study time of 12.5 hours per week with a standard deviation of 7.0.  Use a .05 alpha level to test the statistical significance of the observed difference between means.*

::: {.center}
[$H_0: \mu_{UW} - \mu_{WSU} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em"} [$H_a: \mu_{UW} - \mu_{WSU} \ne 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px;font-size: 1.25em"}
:::

<br>

::: {.fragment .fade-out fragment-index=1 style="text-align: center; color: #a68100"}
Standard error<br>(s.d. of the sampling distribution)
:::

<br>

::: {.fragment .fade-out fragment-index=2 style="font-size: 2em; text-align: center"}
$t = \frac{(\bar{X_1}-\bar{X_2})-0}{s_{\bar{X_1}}-s_{\bar{X_2}}}$
:::

::: {.fragment .fade-out fragment-index=2 style="border: 3px solid #a68100; width: 125px; height: 45px; position: absolute; bottom: 15px; left: 495px"}
:::

::: {.fragment fragment-index=1 style="font-size: 1.5em; text-align: center; position: absolute; bottom: 150px; left: 50px;"}
::: {.fragment .fade-out fragment-index=3}
$s_{\bar{X_1} - \bar{X_2}} = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}} = \sqrt{\frac{8.25^2}{100} + \frac{7.0^2}{81}} = \sqrt{0.681 0.605} = 1.134$ 
:::
:::

::: {.fragment .fade-in fragment-index=2}
::: {.fragment .grow fragment-index=2 style="font-size: 1.5em; text-align: center; position: absolute; bottom: 25px; left: 350px;"}
$t = \frac{(14 - 12.5)-0}{1.134} = 1.764$
:::
:::

::: {.fragment fragment-index=3 style="font-size: 1em; text-align: center; position: absolute; bottom: 150px; left: 50px;"}
Observed sample difference is [1.764]{style="color: #1b8883"} standard errors away from the assumption of the null hypothesis 
:::


## Two-sample hypothesis test

#### Make a decision (Reject/fail to reject $H_0$ and support/fail to support $H_a$)

*We want to know if UW students differ from WSU students in terms of average study time.  We draw a random sample of 100 UW students and find an average study time of 14.5 hours per week with a standard deviation of 8.25.  In contrast, our random sample of 81 WSU students has an average study time of 12.5 hours per week with a standard deviation of 7.0.  Use a .05 alpha level to test the statistical significance of the observed difference between means.*

::: {.center}
[$H_0: \mu_{UW} - \mu_{WSU} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; padding: 5px 5px 5px 5px; font-size: 1.25em"} [$H_a: \mu_{UW} - \mu_{WSU} \ne 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; padding: 5px 5px 5px 5px;font-size: 1.25em"}
:::

<br>

::: {.incremental style="font-size: 0.85em; text-align: center; position: absolute; bottom: 130px; left: 50px;"}
* Since our test statistic ([$1.764$]{style="color: #1b8883"}) is LESS extreme than the critical value ([$1.990$]{style="color: #e93cac"}) we [**FAIL TO REJECT** $H_0$]{style="background: #c5b4e3"}
    * Based on this evidence, it is NOT safe to say that the [population]{.underline} of UW students and the [population]{.underline} of WSU students differ in terms of average study time.
        * The observed difference between sample means is [NOT statistically significant]{.underline}
:::


::: {style="font-size: 1.95em; text-align: center; position: absolute; bottom: 15px; left: 295px;"}
$t = \frac{(14 - 12.5)-0}{1.134} = 1.764$
:::

## Practice

#### Two-sample hypothesis test

*We want to know if high school students have more Facebook (FB) friends than do senior citizens. A random sample of 30 high school students shows a mean number of FB friends of 245 with a standard deviation of 90.  In contrast, a random sample of 40 senior citizens (age 65+) has a mean of 185 FB friends with a standard deviation of 65. Use a .05 alpha level to test the statistical significance of the observed difference between means.*

## Practice {visibility="hidden"}

#### Two-sample hypothesis test

*We want to know if high school students have [more]{style="color: #1b8883;"} Facebook (FB) friends than do senior citizens. A random sample of [30]{style="color: #a68100;"} high school students shows a mean number of FB friends of 245 with a standard deviation of 90.  In contrast, a random sample of [40]{style="color: #a68100;"} senior citizens (age 65+) has a mean of 185 FB friends with a standard deviation of 65. Use a [.05 alpha level]{style="color: #e93cac;"} to test the statistical significance of the observed difference between means.*

:::: {.columns}

::: {.column width="40%"}
::: {.fragment fragment-index=1}
[$H_0: \mu_{HS} - \mu_{SC} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 125px; padding: 5px 5px 5px 5px; text-align: center; font-size: 0.8em"} [$H_a: \mu_{HS} - \mu_{SC} \gt 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 125px; padding: 5px 5px 5px 5px; text-align: center; font-size: 0.8em"}
:::
<br>

::: {.fragment fragment-index=2 style="text-align: center;"}
Critical value of t?
:::

<br>


:::

::: {.column width="60%"}

::: {.fragment fragment-index=1}
* Population standard deviation is unknown



* Use the sample standard deviation to estimate the standard error

$$
s_{\bar{X_1} - \bar{X_2}} = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}} = \sqrt{\frac{90^2}{30} + \frac{65^2}{40}} = \sqrt{270 + 105.625} = 19.381
$$




* Use the t-distribution^[[Table](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm) from your textbook or an [online calculator](https://goodcalculators.com/student-t-value-calculator/)] with $df = n - 1$



[$df = 30 - 1 = 29$]{.center}
:::


:::

::::

## Practice {visibility="hidden"}

#### Two-sample hypothesis test

*We want to know if high school students have [more]{style="color: #1b8883;"} Facebook (FB) friends than do senior citizens. A random sample of [30]{style="color: #a68100;"} high school students shows a mean number of FB friends of 245 with a standard deviation of 90.  In contrast, a random sample of [40]{style="color: #a68100;"} senior citizens (age 65+) has a mean of 185 FB friends with a standard deviation of 65. Use a [.05 alpha level]{style="color: #e93cac;"} to test the statistical significance of the observed difference between means.*

:::: {.columns}

::: {.column width="40%"}

[$H_0: \mu_{HS} - \mu_{SC} = 0$]{style="background: #c5b4e3; border: 4px solid #754cbc; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; text-align: center; font-size: 0.8em"} [$H_a: \mu_{HS} - \mu_{SC} \gt 0$]{style="background: #aadb1e; border: 4px solid #6e8e13; border-radius: 15px; width: 150px; padding: 5px 5px 5px 5px; text-align: center; font-size: 0.8em"}

<br>


::: {style="text-align: center;"}
Critical value of t = [1.699]{style="color: #e93cac"}
:::

<br>

::: {.fragment fragment-index=1 style="font-size: 1em"}
Test statistic from the sample:<br>
:::

::: {.fragment fragment-index=1 style="font-size: 1.25em; text-align: center"}
$t = \frac{\bar{X}-\mu_0}{s_\bar{X}} = \frac{(245-185)-0}{19.381} =$<br><br>[$3.096$]{style="color: #1b8883; border: solid #1b8883; padding: 5px 5px 5px 5px"}
:::


:::

::: {.column width="60%"}

::: {.fragment .fade-out fragment-index=2}
* Population standard deviation is unknown



* Use the sample standard deviation to estimate the standard error

$$
s_{\bar{X_1} - \bar{X_2}} = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}} = \sqrt{\frac{90^2}{30} + \frac{65^2}{40}} = \sqrt{270 + 105.625} = 19.381
$$




* Use the t-distribution with $df = n - 1$



[$df = 30 - 1 = 29$]{.center}
:::


:::

::::

::: {.fragment fragment-index=2 style="border: 4px solid black; border-radius: 15px; width: 550px; padding: 5px 5px 5px 5px; position: absolute; top: 350px; right: 0px; text-align: center"}
Since [obtained t]{style="color: #1b8883"} is MORE extreme than the [critical value]{style="color: #e93cac"}, we **REJECT** $H_0$. Based on this evidence, we are reasonably confidence that the population of high schoolers have a [higher average number]{style="color: #6e8e13"} of FB friends than do senior citizens. The observed difference between sample means is **statistically significant**. 
:::


# Homework{.section-title background-color="#e8e3d3"}

## {data-menu-title="Homework 5" background-iframe="https://vsass.github.io/SOC221/homework/homework5.html" background-interactive=TRUE}


